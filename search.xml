<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[本地日志分析上报脚本实现思路梳理]]></title>
    <url>%2F2016%2F07%2F16%2FlogAgent%2F</url>
    <content type="text"><![CDATA[背景 目前我们部门的日志查询只能通过开发人员登录对应的机器执行日志分析，效率不够高效。对于现网问题，由于运维不理解后台模块的日志含义，因此只能由开发去现网机器查询日志；对于联调环境，接入方调用接口出了问题只能通过我们部门后台开发人员协助解决。这种强依赖指定开发人员的情况，不利于问题的快速解决。因此我们迫切的需要一个日志中心来处理和查询所有的日志，并且由于需要在联调时能够让接入方自己定位问题，我们对实时性也有一定的要求。但是由于公司没有提供这种系统，所以我们决定自己做一个日志模块来处理上述问题。这篇文章主要是写一下日志模块客户端的实现思路，对于日志存储查询服务由于不是我开发，所以只做简单介绍。 在模块内部实现最开始的实现方式是修改业务逻辑代码，在需要上报日志的地方增加日志上报逻辑，但是由于php语言不支持装饰器和注解这样的语法，因此这样的实现对于业务代码的入侵度极高，同时需要大量修改业务代码已有的处理流程，也存在着很大的风险。同时由于增加了日志上报逻辑，因此多了一次网络调用，如果日志服务存在故障，那么网络调用超时会影响业务逻辑，这是很不合理的实现方案，因此我这样写了两天代码就写不下去了。 优化后来看了下CI框架的文档，发现CI也支持钩子语法，因此可以通过设置一个全局的钩子来实现对关键日志的监控，所谓钩子，其实就是框架主流程埋几个点，这样你就可以在框架执行流程中增加自己的逻辑来影响框架执行流程，我当时挂钩点是控制器初始化完成，但调用构造器之前。这样的实现看起来很简单，也减少了代码入侵，但是仅仅是减少代码入侵而已，对于所有的流程还是会经过日志判断，运行流程上面还是和最开始的实现方式一样，是全局的。另外一点很不好的地方就是需要设置几个全局变量来存储一些钩子获取不到的数据，如网络调用，这样对于后来的维护者很难理解为什么这里会有一个全局变量赋值，然后就吐槽一番这个代码顺便删除，然后我们的日志监控就呵呵了。因此这样的实现方案也是不太好的。所以我把代码回滚，放弃了这种做法。。 通过本地日志agent脚本实现接下来就是本文的重点啦~ 最后决定通过本地写个脚本来实时分析日志并且上传到日志模块来实现日志的监控。这个方案是我认为最合理的方案，同时也是很多企业的做法。实现方案确定好了以后，接下来的就是评估技术方案了。 python脚本循环读取日志存储目录实现监控先看一下一天产生的日志总量：1234567891011121314151617181920212223242526272829303132333435363738[bradykang@10_113_88_21 /data/log/trade]$ du -ch ./trade_20160716_* | grep total14G total[bradykang@10_113_88_21 /data/log/trade]$ du -ch ./trade_20160715_* | grep total17G total[bradykang@10_113_88_21 /data/log/trade]$ du -ch ./trade_20160714_* | grep total16G total[bradykang@10_113_88_21 /data/log/trade]$ du -ch ./trade_20160713_* | grep total15G total[bradykang@10_113_88_21 /data/log/trade]$ du -ch ./trade_20160712_* | grep total14G total[bradykang@10_113_88_21 /data/log/trade]$ du -ch ./trade_20160711_* | grep total15G total[bradykang@10_204_187_173 /data/log/trade]$ du -ch ./trade_20160716_* | grep total8.6G total[bradykang@10_204_187_173 /data/log/trade]$ du -ch ./trade_20160715_* | grep total9.5G total[bradykang@10_204_187_173 /data/log/trade]$ du -ch ./trade_20160714_* | grep total11G total[bradykang@10_204_187_173 /data/log/trade]$ du -ch ./trade_20160713_* | grep total9.6G total[bradykang@10_204_187_173 /data/log/trade]$ du -ch ./trade_20160712_* | grep total8.4G total[bradykang@10_204_187_173 /data/log/trade]$ du -ch ./trade_20160711_* | grep total8.8G total[bradykang@10_204_238_40 /data/log/trade]$ du -ch ./trade_20160716_* | grep total20K total[bradykang@10_204_238_40 /data/log/trade]$ du -ch ./trade_20160715_* | grep total43M total[bradykang@10_204_238_40 /data/log/trade]$ du -ch ./trade_20160714_* | grep total50M total[bradykang@10_204_238_40 /data/log/trade]$ du -ch ./trade_20160713_* | grep total156M total[bradykang@10_204_238_40 /data/log/trade]$ du -ch ./trade_20160712_* | grep total499M total[bradykang@10_204_238_40 /data/log/trade]$ du -ch ./trade_20160711_* | grep total241M total 综上统计：三台机器一天的日志产生量在25G左右。这还只是一个在模块一天的日志产生量，所有模块加起来的话应该在百G以上。所以要实时监控性能很重要 之前有位大神给我讲过他之前是怎么做一个日志监控的，他当时告诉我是本地写了一个脚本来实现，所以我第一想法就是写个python脚本。但是写了一段时间发现越写越没谱，主要是因为现网的日志一天的量是以T为单位，而我的逻辑里面包含了很多的文件IO(因为要实时监控，所以要一直读取文件夹监控内部的变化)。所以这样做的话，很可能会出现分析跟不上产生的节奏，这样实时性很差且会产生一定的系统负载，因此这种实现被放弃了。 后来想了想，突然记起之前在学校做得一个项目，项目里面有个知识点是关于linux文件系统监控的，即linux文件系统的inotify机制，关于该机制的介绍我就不做过多篇幅的描述了，参见这篇wikiinotify。 所以我完全可以去网上下个python实现的文件系统notify库，然后就可以很方便的监控到文件系统的变化了。但是突然想起后面还有那么多的字符分析，好像用python的话性能不能满足我们对实时性要求高的需求，因此我决定使用shell命令来做这个脚本。那些设计优美且性能高效的文本分析命令完全可以很方便的实现我对于日志分析的要求。而且这样我的全部工作就是组装命令，维护日志分析的主逻辑了。 shell通过notify_tools实现日志分析shell实现有几个技术问题需要解决，第一是文本处理命令的选择；第二是notify_tools是否真能满足要求；第三则是性能测试了 文本命令的选择123456789101112131415# 普通字符过滤性能比较[root@mcs/data/log/trade.logical]# time grep ".*atom" log-2016-07-16.log&gt;/dev/nullreal 0m0.194suser 0m0.188ssys 0m0.004s[root@mcs /data/log/trade.logical]# time sed "/.*atom/p" log-2016-07-16.log&gt;/dev/nullreal 0m0.201suser 0m0.192ssys 0m0.008s[root@mcs/data/log/trade.logical]# time awk "/.*atom/" log-2016-07-16.log&gt;/dev/nullreal 0m1.502suser 0m1.484ssys 0m0.016s 可以看出来这三者的性能排序为grep&gt;sed&gt;awk，awk基本不考虑使用了，最然它给我们提供了可编程的空间，但是太慢了。至于最快的grep，由于它在命令上支持不够丰富，所以也不考虑使用。因此选取性能和功能相对而言优于其他两者的sed命令。当然，这只是一个简单的测试，由于我缺乏对这三个命令高级选项的认识，因此这三个命令在加了高级选项以后的性能排序可能有所不同。但是对目前的需求而言，执行这样的测试然后选择sed是没有问题的。 notify_tools是否满足要求这个就简单了，通过执行man inotifywait看了下文档，发现这个工具是满足我们的要求的 性能测试待补充…. shell脚本实现方案有几点需要首先明确，这个日志分析脚本由于是在本机运行，所以必然会部署多份，虽然我们部门只有几台服务器，但也勉强算个分布式了==。所以脚本的运行应该足够简单，所以决定通过配置文件来控制脚本的运行。 另外一点就是如何保证日志文件都是被处理完了，不会出现漏处理或者处理速度跟不上的问题。这个的实现我是通过维护一个处理偏移量的文件来记录脚本处理的文件位置信息，方便脚本中断后能够从上次的处理位置继续处理。 由于一次产生的日志量很大，所以不能够一行一行的处理，这样或许能够跟上日志的产生速度，但是不太合理，我采用的方案如下： 循环的执行监听命令，当收到文件变化的通知后便立刻进行处理 如果通知的变化文件和偏移量中记录的文件一致，则计算出当前文件总行数（主要是为了避免一直变化的行数造成处理混乱），从上次记录的偏移量处理到当前文件的总行数 如果通知的变化文件和偏移量中记录的文件不一致，这个时候说明发生了新建日志文件的动作，则一次性处理完偏移量文件中记录的文件的剩下的所有内容，并且开始处理新创建的日志文件 更新偏移量和指向文件 这样的实现有个特点就是，在日至量增加特别特别快的情况下（万行每秒），处理脚本可能会出现延后，且日志增量如果不降下去，处理会越来越延后，但是当新建文件时，脚本会一次性将所有延后处理的日志一次性全部处理了，通过动态获取处理量来避免大量日志产生对于实时性的降低。 当然缺点也是很明显的，如果日志量增加的速率一直增加，那么日志处理肯定是会有延后的，同时如果是通过调用接口上报日志的话，日志仍然会有几秒甚至几十秒左右的延后。但是对于我们的系统，目前这样实现是够用了，业务量上去还可以通过优化脚本和优化日志服务的方式来提高日志的处理速度。对于联调环境的日志量，这样的实现完全可以胜任。 接下来的事情就是让时间去验证这样实现的优缺点。 后续改进方案 目前这个脚本的耗时主要在日志的网络传输上（即传到日志中心的这个过程），采用的直接插入数据库或者调用接口。 日志中心废弃数据库的存储方式，采用更适合文本检索的文件存储方式来分析存储日志。 本地不再分析日志，只负责将日志提取出来发送给日至中心，分析由日至中心处理完成，但是降低了实时性。 传输协议上面可以用thrift协议，而不是现在的http协议或者直插数据库。 规范化系统后台日志格式，提高程序的整洁和日志信息的可读性。 最后贴一段脚本的部分代码来凑凑篇幅1234567891011121314151617181920212223242526272829303132333435363738394041#!/bin/sh# 偏移量文件格式：偏移量 指向文件configFile=$1declare -a configArrwhile IFS='' read -r line || [[ -n "$line" ]]; do IFS='=' read -r key value &lt;&lt;&lt; "$line" configArr[$key]=$valuedone &lt; "$configFile"echo -e "parse config file succ \n\nstart watch log file[log path:$&#123;configArr['logCategoryPath']&#125;]\n"while watchInfo=`inotifywait -q --format '%e %f' -e modify,create $&#123;configArr['logCategoryPath']&#125;`;do watchInfo=($watchInfo) lines=`wc -l $&#123;watchInfo[1]&#125;` offsetInfo=`cat $&#123;configArr['offsetFilePath']&#125;` # 如果偏移量文件不存在，则创建偏移量文件 if [ $? ]; then # 如果偏移量记录文件为空，则初始化偏移量，从第0行读取变更的文件 if [ $offsetInfo -eq "" ]; then process 1 $&#123;lines&#125; $watchInfo[1] # 如果偏移量文件不为空，则取出偏移量和指向的文件 else offsetInfo=($offsetInfo) if [ $&#123;offsetInfo[1]&#125; -eq $&#123;watchInfo[1]&#125; ]; then # 处理上一个日志文件 process $&#123;offset&#125; $ $offsetFile # 处理从第0行开始处理新创建的文件 process 1 $&#123;lines&#125; $watchInfo[1] else # 继续处理偏移量文件中记录的文件 process $&#123;offset&#125; $&#123;lines&#125; $watchInfo[1] fi fi # 处理完成，更新偏移量和指向的文件 cat "$lines $&#123;watchInfo[1]&#125;" &gt; $&#123;configArr['offsetFilePath']&#125; else touch $&#123;configArr['offsetFilePath']&#125; fidone 目前实现方案在联调环境中的试运行发现shell实现扩展性，维护性和可操作性都比较差，因此换用python实现，采用多线程和子进程的方式实现，同时对于协议的支持也更加完善，配置也支持更多选项。]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>notify</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[web开发中的浏览器跨域整理]]></title>
    <url>%2F2016%2F07%2F15%2Fcors_summary%2F</url>
    <content type="text"><![CDATA[HTTP访问控制(CORS)同源策略同源政策的目的，是为了保证用户信息的安全，防止恶意的网站窃取数据。设想这样一种情况：A网站是一家银行，用户登录以后，又去浏览其他网站。如果其他网站可以读取A网站的 Cookie，会发生什么？很显然，如果 Cookie 包含隐私（比如存款总额），这些信息就会泄漏。更可怕的是，Cookie 往往用来保存用户的登录状态，如果用户没有退出登录，其他网站就可以冒充用户，为所欲为。因为浏览器同时还规定，提交表单不受同源政策的限制。由此可见，”同源政策”是必需的，否则 Cookie 可以共享，互联网就毫无安全可言了。为什么不能跨域访问跨域并非浏览器限制了发起跨站请求，而是跨站请求可以正常发起，但是返回结果被浏览器拦截了。最好的例子是CSRF跨站攻击原理，无论是否跨域，请求是发送到了后端服务器，注意：有些浏览器不允许从HTTPS的域跨域访问HTTP，比如Chrome和Firefox，这些浏览器在请求还未发出的时候就会拦截请求，这是一个特例。所以只有服务器允许跨域，并且在相应包的头信息里面指明允许跨域，那么跨域请求的响应数据就不会被浏览器拦截丢弃了。 什么是跨域 URL1 URL2 是否跨域 原因 http://kangbiao.org/index https://kangbiao.org/index 是 协议不同 http://kangbiao.org/index http://kangbiao.org:8080/index 是 端口号不同 http://kangbiao.org/index http://baidu.org/index 是 主机不同 http://kangbiao.org/index http://t1.kangbiao.org/index 是 主机不同 通过上面的比较可以归纳出，跨域是指协议、主机地址、端口号这三个条件只要有一个不同则认为是跨域。 六种跨域方式通过浏览器对象解决document.domain(适用于子域跨域)在同源策略中有一个例外，脚本可以设置 document.domain 的值为当前域的一个后缀，如果这样做的话，短的域将作为后续同源检测的依据。例如，假设在 http://t1.kangbiao.org/index 中的一个js脚本执行了下列语句：document.domain = “kanbgiao.org”;这条语句执行之后，页面将会成功地通过对 http://company.com/index 的同源检测。但是不能通过设置 document.domain = “notkangbiao.org”;完成对其他域的访问，该方法只适用于子域和父域之间的跨域解决。 使用document.domain来让子域安全地访问其父域，需要同时将子域和父域的document.domain设置为相同的值，没有这么做的话会导致授权错误。 window.name这种方案实用性不高，实现也挺麻烦，也不够灵活，所以我就不详细写了，有兴趣可以参考这篇文章 客户端和服务端配合实现jsonpjsonp其实就是动态创建js脚本。虽然浏览器默认禁止了跨域访问，但并不禁止在页面中引用其他域的JS文件，并可以自由执行引入的JS文件中的函数，因此可以将script的src属性设为需要跨域的接口地址，但是需要服务器将数据组装成js变量定义或者函数传回来，举例如下：比如kangbiao.org/index 需要调用t1.kangbiao.org/getServerInfo接口获取服务器信息，原来该接口的返回是:12345&#123; "ip":"192.168.1.1", "cpu":"Intel i5", "network":"100M"&#125; 现在为了配合jsonp的话返回格式应该如下：12345 var response=&#123; "ip":"192.168.1.1", "cpu":"Intel i5", "network":"100M"&#125;; 所以jsonp就是在返回数据中定义一个js变量或者函数来实现动态创建js脚本，这样做的缺点也显而易见，会出现变量污染或者函数重名(可以通过生命一个服务器专用的函数对象解决)，而且服务器和前端脚本变量绑定太强，不是很灵活。 采用HTML5中的postMessage解决postMessage可以实现窗口和窗口，页面和iframe，页面和窗口间的跨域通信。postMessage需要源网站和跨域网站同时实现两个接口postMessage(发送数据)和addEventListener(监听事件，接受数据) otherWindow.postMessage(message, targetOrigin); otherWindow其他窗口的一个引用，比如iframe的contentWindow属性、执行window.open返回的窗口对象、或者是命名过或数值索引的window.frames。 message将要发送到其他 window的数据。 targetOrigin通过窗口的origin属性来指定哪些窗口能接收到消息事件，其值可以是字符串”*“（表示无限制）或者一个URI。在发送消息的时候，如果目标窗口的协议、主机地址或端口这三者的任意一项不匹配targetOrigin提供的值，那么消息就不会被发送；只有三者完全匹配，消息才会被发送。这个机制用来控制消息可以发送到哪些窗口；例如，当用postMessage传送密码时，这个参数就显得尤为重要，必须保证它的值与这条包含密码的信息的预期接受者的orign属性完全一致，来防止密码被恶意的第三方截获。如果你明确的知道消息应该发送到哪个窗口，那么请始终提供一个有确切值的targetOrigin，而不是*。不提供确切的目标将导致数据泄露到任何对数据感兴趣的恶意站点。 target.addEventListener(type, listener[, useCapture]); type表示所监听事件类型的一个字符串。 listener当指定的事件类型发生时被通知到的一个对象。该参数必是实现EventListener 接口的一个对象或函数。 useCapture 可选如果值为true， useCapture表示用户希望发起捕获。 在发起捕获之后， 只要Dom子树下发生了该事件类型，都会先被派发到该注册监听器，然后再被派发到Dom子树中的注册监听器中。并且向上冒泡的事件不会触发那些发起捕获的事件监听器。进一步的解释可以查看 DOM Level 3 Events 文档。 请注意该参数并不是在所有的浏览器版本中都是可选的。如果没有指定， useCapture默认为false 。 两个函数的定义如上，addEventListener不是html5中特有的，postMessage是html新增实现跨域通信的。如果需要跨域交换数据，则需要两边都需要同时实现这两个接口，才能交换数据，不然只能单方向的接收或者发送数据。一般的实现是在addEventListener的回掉函数中通过event.data获取到传过来的数据后，再次调用postMessage将处理后的数据返回给消息来源对象。这样实现好处就是完全不需要后端的参与。但是有一定的安全风险，配合xss可以导致用户凭证信息被盗取。具体的代码示例参考postMessage实示例 服务器响应头控制(CORS 跨域资源共享)这种方法是我认为最好的方法，由服务器决定是否允许跨域，如果允许，服务器在响应头中添加相应的字段告诉浏览器此次跨域合法，则浏览器不会将请求包丢弃(文章开头说了跨域其实是浏览器的一种行为)，从而完成跨域。这种方法的详细操作我就不多说了，参考廖雪峰的这篇文章主要叙述下服务端怎么设置响应头在PHP中可以中国header()函数设置允许跨域字段在java中可以通过设置reponse.setHeader()函数来设置，spring4.2及以上版本提供了@CrossOrigin注解来方便实现跨域。 服务器代理服务器代理就是将需要跨域访问的地址通过服务器访问(服务器此时作为客户端，不会受同源策略限制)，然后由服务器返回结果。例如kangbiao.org/index 页面需要访问api.weibo.com/getNews 来获取最新新闻，我们可以通过在kangbiao.org的服务器上面多增加一个接口 kangbiao.org/api?url=api.weibo.com/getNews ，然后再服务器内部，该接口所做的事情就是向api.weibo.com/getNews 发起请求即可，然后将结果返回。这样做的好处是实现十分简单，而且可以访问任何跨域站点，缺点就是需要新增维护一个接口，而且如果服务器是通过代理网关，只能内网通信的话也很麻烦。 反向代理反向代理也是在服务器实现的，主要是通过正则匹配url，匹配成功后重写到目标地址即可，这种方法可以实现所有网站的跨域，不需要服务器提供跨域支持，个人认为比较方便，甚至可以配置kangbiao.org/proxy/weibo/实现将api.weibo.com域的接口整合到我们自己的网站下面来，并且程序不需要做任何改动，改下nginx的配置文件即可。具体的实现方案很多，google或者百度nginx反向代理实现跨域即可。 参考文章 firefox开发者文档-CORS firefox开发者文档-postMessage 维基百科-BOM]]></content>
      <categories>
        <category>web前端</category>
      </categories>
      <tags>
        <tag>跨域</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WebSocket加RabbitMQ实现web应用实时获取服务器推送]]></title>
    <url>%2F2016%2F07%2F10%2Fwebsocket-with-rabbitmq%2F</url>
    <content type="text"><![CDATA[这篇文章主要记录一下通过实现一个实时获取推送的web应用从而加深对WebSocket的理解，至于为什么用RabbitMQ，只是因为我想顺便熟悉一下这个消息中间件。 基本概念传统Web应用实现长连接的方式CometComet_维基百科#.E9.95.BF.E8.BD.AE.E8.AF.A2) Ajax 短轮询Ajax 轮询主要通过页面端的 JS 定时异步刷新任务来实现数据的加载 WebSocketWebSocket 是 HTML5 中一种新的通信协议，能够实现浏览器与服务器之间全双工通信。 RabbitMQ环境准备 环境准备参考官网即可，一般情况下不会出现问题，出现问题主要是依赖问题，根据提示安装好依赖就行。本文重点在于实现一个实时获取推送的web应用，工具的使用请参考官方文档。 erlang安装 百度erlang按照官网的教程走就行了。 123456789101112131415161718192021222324252627error: Failed dependencies: libGLU.so.1()(64bit) is needed by esl-erlang-19.0-1.x86_64 libwx_baseu-2.8.so.0()(64bit) is needed by esl-erlang-19.0-1.x86_64 libwx_baseu-2.8.so.0(WXU_2.8)(64bit) is needed by esl-erlang-19.0-1.x86_64 libwx_baseu_xml-2.8.so.0()(64bit) is needed by esl-erlang-19.0-1.x86_64 libwx_gtk2u_adv-2.8.so.0()(64bit) is needed by esl-erlang-19.0-1.x86_64 libwx_gtk2u_adv-2.8.so.0(WXU_2.8)(64bit) is needed by esl-erlang-19.0-1.x86_64 libwx_gtk2u_aui-2.8.so.0()(64bit) is needed by esl-erlang-19.0-1.x86_64 libwx_gtk2u_aui-2.8.so.0(WXU_2.8)(64bit) is needed by esl-erlang-19.0-1.x86_64 libwx_gtk2u_aui-2.8.so.0(WXU_2.8.5)(64bit) is needed by esl-erlang-19.0-1.x86_64 libwx_gtk2u_core-2.8.so.0()(64bit) is needed by esl-erlang-19.0-1.x86_64 libwx_gtk2u_core-2.8.so.0(WXU_2.8)(64bit) is needed by esl-erlang-19.0-1.x86_64 libwx_gtk2u_gl-2.8.so.0()(64bit) is needed by esl-erlang-19.0-1.x86_64 libwx_gtk2u_gl-2.8.so.0(WXU_2.8)(64bit) is needed by esl-erlang-19.0-1.x86_64 libwx_gtk2u_html-2.8.so.0()(64bit) is needed by esl-erlang-19.0-1.x86_64 libwx_gtk2u_html-2.8.so.0(WXU_2.8)(64bit) is needed by esl-erlang-19.0-1.x86_64 libwx_gtk2u_stc-2.8.so.0()(64bit) is needed by esl-erlang-19.0-1.x86_64 libwx_gtk2u_stc-2.8.so.0(WXU_2.8)(64bit) is needed by esl-erlang-19.0-1.x86_64 libwx_gtk2u_xrc-2.8.so.0()(64bit) is needed by esl-erlang-19.0-1.x86_64 libwx_gtk2u_xrc-2.8.so.0(WXU_2.8)(64bit) is needed by esl-erlang-19.0-1.x86_64如果出现上述错误，说明是缺少依赖，执行以下两行命令即可# yum -y install make gcc gcc-c++ kernel-devel m4 ncurses-devel openssl-devel java-devel unixODBC-devel;# yum install unixODBC unixODBC-devel wxBase wxGTK SDL wxGTK-gl最后执行`erl`，如果进入了erlang的交互式shell，则说明安装成功。# erl rabbitmq安装 还是按照官网教程走就行了，这里有个坑就是如果erlang是通过rpm包安装的话会出现rabbitmq依赖的erlang版本错误的问题，估计是由于一些环境变量不对，这里我也没有多折腾，较快的解决方案是使用yum安装一次就好了。 安装好rabbitmq后，执行以下命令启用web管理扩展，这样就可以通过web端来查看rabbitmq的运行状态 12345678910# rabbitmq-plugins enable rabbitmq_management rabbitmq_web_stomp rabbitmq_stomp但是由于rabbitmq_management的默认设置，此时只能通过localhost访问rabbitmq的web管理端。新建/etc/rabbitmq/rabbitmq.config文件，加入如下配置即可解决[&#123;rabbit, [&#123;loopback_users, []&#125;]&#125;].最后重启rabbitmq使更改生效。# service rabbitmq-server restart然后就可以通过http://ip:15672来访问到rabbitmq的web管理端。 java环境配置略 测试待更新]]></content>
      <categories>
        <category>CS原理</category>
      </categories>
      <tags>
        <tag>WebSocket</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为PHPStorm开发一个在内网通过SSH代理隧道实现一键代码同步功能的插件]]></title>
    <url>%2F2016%2F06%2F20%2Fphpstorm-filesync-plugin%2F</url>
    <content type="text"><![CDATA[写在前面：开发这个插件的背景是我所在的公司的测试环境的机器是不能够直接在本地通过SSH登陆上去的，需要先SSH登陆到一个跳板机上面，然后再跳板机上面SSH登陆到测试环境的机器上面。另外一个比较坑的地方就是测试环境的机器和代码仓库的网络是不通的，所以测试环境的代码部署是通过sz命令一个一个本地上传（对，压缩包都不能传），另外本地电脑的网络和测试环境完全隔离，测试是通过在测试机器上面发包实现。 讲道理，这是一种很笨拙的做法，但是由于公司网络限制，又没有办法。然而自从前段时间不小心看见了一片关于Xshell代理隧道实现内网访问的文章，下来仔细想了想，竟然可以通过这个方法来实现本地直接访问测试环境，发测试请求包等等。后来又想到可不可以写一个PHPStorm插件实现在编辑器右键然后可以在弹出菜单里面选择一个同步到测试环境或者从测试环境同步实现一键代码同步。 所以这篇文章主要会记录一下几个知识点： 三种SSH代理的区别和原理。 jsch实现跳板机多次ssh登陆的原理。 基于jetbrains(phpstorm，idea，pycharm等)的IDE的插件开发介绍。 怎样实现用户可配置插件和怎样在插件中通过jsch实现SSH代理。 一些其他的坑。 加班太多，还没写好，待更新。。。]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>idea插件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis高性能SDS字符串实现分析]]></title>
    <url>%2F2016%2F04%2F30%2Fredis-sds%2F</url>
    <content type="text"><![CDATA[字符串在C语言中的存储方式 在C语言中，采用长度为N+1的字符数组来存储一个长度为N的字符串，最后一个字符是空字符\0，表示字符串的结尾。 在C语言中，增加或者减少字符串的长度都涉及内存空间的重新分配，这是很耗时的，对于一个作为数据库的应用redis来说，直接使用这种方式会严重影响性能。C语言对字符串的操作过程如下： 如果增加字符串的长度的话，在操作之前需要通过重新分配内存来扩展存储该字符串底层数组的长度，否则会发生缓冲区溢出。 如果减少字符串长度的话，在操作之前同样需要重新分配内存释放多余的内存空间，不重新分配内存虽然不会直接造成程序崩溃，但是当这种操作多了以后，就会有大量的空闲的内存空间而导致内存泄漏问题。 Redis字符串存储方案SDS存储的结构体12345struct sdshdr&#123; int len; //buf数组中已经使用的字节的数量，也就是SDS字符串长度 int free; //buf数组中未使用的字节的数量 char buf[]; //字节数组，字符串就保存在这里面&#125;; redis通过定义结构体的方式，扩展了C语言底层字符串的缺点，字符串长度的获取时间复杂度从原来的O（N）变成了O（1），另一方面也可以通过free的动态改变减少内存的分配。需要强调一点的是buf数组不是存储的字符，而是二进制数组，因为C语言字符串中间是不能出现空字符的，而二进制数据中间很有可能会有空字符，所以C语言是二进制不安全的，而redis又是二进制安全，为了存储多种类型的数据，redis就直接把所有数据当作二进制来存储，这样就可以存储媒体文件和字符串，所以SDS虽然叫简单动态字符串，但是它可不只是用来保存字符串哦 buf数组动态分配策略 既然redis定义了一个结构体来描述一个SDS字符串，多出来的几个变量肯定是有很大作用的，其中一个很重要的作用就是实现对字符串的灵活操作并且尽量减少内存重新分配和回收操作。 redis的内存分配策略如下： 当SDS的len属性长度小于1MB时，redis会分配和len相同长度的free空间。至于为什么这样分配呢，我觉得这个有点像一种惯性预测。举个例子，比如一个乞丐向你要10块钱，如果让你预测下一个乞丐会让你要多少，这个时候我没有其他的依据，当然就只能根据上一个乞丐的行为来推测下一个乞丐会让我要10块啦~放到redis里面，上次用了len长度的空间，那么下次程序可能也会用len长度的空间，所以redis就为你预分配这么多的空间。 但是当SDS的len属性长度大于1MB时，这个时候我在根据这种惯性预测来分配的话就有点得不偿失了，比如修改后的SDS长度为100MB，那我也傻乎乎的给你分配100MB空闲内存等你用么？万一你下次用不了这么多了，对于内存而言就亏大发了。所以，redis是将1MB设为一个风险值，没过风险值你用多少我就给你多少，过了的话那这个风险值就是我能给你临界值，感觉父母给零花钱也是酱紫。。至于为什么是1MB，这个问题就和redis使用的场景有关了。 reids的内存回收策略如下： redis的内存回收采用惰性回收，即你把字符串变短了，那么多余的内存空间我先不还给操作系统，先留着，万一马上又要被使用呢。短暂的持有资源，既可以充分利用资源，也可以不浪费资源。这是一种很优秀的思想。 综上所述，redis实现的高性能字符串的结果就把N次字符串操作必会发生N次内存重新分配变为人品最差时最多发生N次重新分配。]]></content>
      <categories>
        <category>SQL&amp;NoSQL</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[跨级DNS查询问题分析]]></title>
    <url>%2F2016%2F04%2F17%2Fdns-lookup%2F</url>
    <content type="text"><![CDATA[引言 由于有个小项目需要搭个临时的多语言测试环境，所以做了个多级域名来区分不同的语言环境。 操作如下: 在阿里云的控制面板，将t1.kangbiao.org和t2.kangbiao.org两个二级域名分别解析到两台服务器上面。 在t1.kangbiao.org服务器上面安装nginx，修改配置文件，分别添加java.nginx.conf，python.nginx.conf和php.nginx.conf三个配置文件。 设置三个语言环境的访问方式(即修改三个配置文件服务器名)为java.t1.kangbiao.org，py.t1.kangbiao.org和php.t1.kangbiao.org。(完全是强迫症犯了，不想分目录访问三个语言环境的服务)。问题：只有t1.kangbiao.org能正确访问，其他的三级域名均查询不到dns。这就是没有完全理解dns查询过程导致的坑啊。我一直以为把域名解析到服务器后，这个域名对应的下级域名就可以在服务器上面配置，然后就可以实现泛解析或者多下级域名访问。 解决问题nginx配置有问题？对照着nginx的官方文档一个配置一个配置的检查了每个配置文件是否正确，甚至把无关紧要的配置项都改来改去测试是不是配置问件有问题，然而改了一个小时候，完全放弃，这根本不是配置文件的坑好嘛。 网络问题？于是又想是不是公司网络的问题，需要用自己的手机访问了一下，still error。。。于是这个问题原因就被排除了。 DNS解析问题？后来仔细看了看浏览器报的错，感觉这是dns没有配对啊。于是上网查了查dns解析原理。最后基本确定是三级域名没有解析记录导致的。 开始解决在阿里云控制面板增加三个域名解析A记录py.t1，java.t1和php.t1后访问，访问正常。我只是测试性的这样配置一下，没想到阿里云还真支持这种a记录里面带.的解析配置。最后想了想，在用户这样设置的时候，这条解析记录直接就绕过t1.kangbiao.org这个域而生效了。一般我们设置php.t1.kangbiao.org解析后的DNS查询如下： 浏览器查询本地缓存，没有则会像ISP的dns发起查询，如果ISP的DNS也没有缓存，则一级一级的去查询解析记录。 由于每一次的查询，浏览器都是带着完整的域名php.t1.kangbiao.org去查询，所以即使没有设置t1.kangbiao.org的解析记录，仍然可以直接查到php.t1.kangbiao.org对应的主机。 所以，dns查询过程并不是一定要老老实实的对每一级域进行查询，只要有记录，是可以跳级去查询的。并不是每个域都要有解析记录。比如一台DNS服务器上面有kangbiao.org和php.t1.kangbiao.org两条解析记录，而t1.kangbiao.org没有解析记录时，那么当去查询php.t1.kangbiao.org时，这台DNS服务器并不是告诉你t1.kangbiao.org对应的服务器是哪一台，而是直接就返回php.t1.kangbiao.org的地址。所以域名在DNS解析里面是字符串式的查询，是不分域的，也就是可以不是一层一层的查询，而是这个域名对应的字符串有解析记录我就返回给你，当查不到时，会返回该DNS服务器已经记录的离该查询域名最近的一个域对应的服务器地址（可能就是该域名本身），分域是针对于浏览器的一个概念 总结所以这下就知道了为什么刚开始只设置t1.kangbiao.org的解析记录，然后再服务器上面设置php.t1.kangbiao.org会访问不到的原因了，因为最后当DNS查询进行到最后一级(即php.t1.kangbiao.org)的时候，是向装有nginx的那台web服务器进行了一次DNS解析查询，明显的那台服务器没有装DNS服务器，所以53号端口就完全没有被开放，所以会直接导致DNS查询失败，在DNS查询里面，分域就是一种协议，大家互相遵守。 教科书上说的果然都是一般情况，技巧性的东西还需多跳坑。]]></content>
      <categories>
        <category>CS原理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[通过Servlet和CGI协议深入理解web数据传输]]></title>
    <url>%2F2016%2F03%2F20%2Fweb-cgi%2F</url>
    <content type="text"><![CDATA[写在前面：由于我自身水平有限，可能文章中有些地方的用词以及概念理解不是很标准，欢迎大家留言指正。这篇文章主要是总结一下我通过学习CGI，然后结合自己的理解对web请求中数据传输的认识。写出来给大家一个参考。 为什么会去研究这个？主要是因为在看公司自己开发的一个php框架的时候，发现自己对web底层数据传输存在疑惑，觉得有必要深入了解一下一个请求怎样通过web服务器(例如nginx，apache)变成编程语言可以处理的数据。 一、基本概念 CGI：即通用网关接口，是一种协议，定义了web服务器和应用程序交互数据的基本格式。例如一个请求发送到nginx后，nginx应该按照CGI协议将请求按照规定的格式处理好后（标准的请求头信息，查询字符串，请求路径等等），然后启用相应的应用程序解析器（php就是php解释器，python就是python解释器），然后把数据传输给解析器，这个时候解析器就可以定位到我们编写的处理代码对请求进行处理，处理完以后按照CGI协议规定的数据格式将结果返回给web服务器，最后退出进程。 fastcgi：fastcgi可以看作是cgi协议的改良版，cgi是通过启用一个解释器进程来处理每个请求，耗时且耗资源，而fastcgi则是通过master-woker形式来处理每个请求，即启动一个master主进程，然后根据配置启动几个worker进程，当请求进来时，master从worker进程中选择一个去处理请求，这样就避免了重复的开启和结束进程带来频繁cpu上下文切换而导致耗时。所以fastcgi也是一种规定了如何实现web服务器和应用程序通信的协议，但是比cgi协议更先进。 几乎所有的语言都可以通过实现CGI或者fastcgi协议编写一个web应用。java的servlet实现是自己规定了一套协议，与这两种方式不同。 二、php结合nginx举例通过cgi实现 用户请求http://www.baidu.com?key=码农&amp;platform=linux。 省略一系列DNS解析然后将数据传输到nginx监听的端口上。 nginx根据配置文件判断该请求是否是静态文件，是的话直接从文件系统读取返回给浏览器。不是的话将接收到的数据进行处理（按照CGI或者fastcgi协议规定的格式），提取出请求头，请求参数，资源路径等信息。 nginx通过配置文件启动一个cgi程序，例如php_cgi，由于php_cgi程序是实现了cgi协议的，所以它能够识别出nginx传过来的数据，然后去执行相应的php文件。 php_cgi将执行后的结果返回给nginx，然后进程退出。 nginx将获得的结果按照http协议规范处理后返回给浏览器。 通过fastcgi实现 Web Server启动时载入FastCGI进程管理器（IIS ISAPI，Apache Module或者php-fpm) FastCGI进程管理器自身初始化，启动多个CGI解释器进程(多个php-cgi)并等待WebServer的连接。 当客户端请求到达Web Server时，FastCGI进程管理器选择并连接到一个CGI解释器。 Web server将CGI环境变量和标准输入发送到FastCGI子进程php-cgi。 FastCGI子进程完成处理后将标准输出和错误信息从同一连接返回Web Server。当FastCGI子进程关闭连接时，请求便告处理完成。FastCGI子进程接着等待并处理来自FastCGI进程管理器(运行在Web Server中)的下一个连接。 三、java实现java的实现不是CGI协议，java servlet是基于多线程来处理每一个请求，即每个请求是在一个线程中去处理，由web容器去维护这个线程池和该每个servlet实例的生存周期。 在java中，是规定了自己的网关数据交互协议（与CGI类似），所以java有自己的web服务器（例如tomcat，jetty等），而不能直接用nginx直接作为web服务器与web容器进行数据交互。java的web服务器可以直接处理来自浏览器的请求，也可以处理来自nginx代理转发的数据，然后将数据重新处理成java web容器能够处理的数据格式。 需要补充一点的是，现在绝大部分java web服务器都实现了web容器的功能，所以很难从实际上去感受这两者之间的区别，但是这种层次关系是存在的。 四、多进程和多线程处理请求的区别 进程内传递数据只是一个引用，同一份数据无需反复多次解析。而FastCGI之类通过IPC、环境变量传递数据，毫无疑问会面临数据序列化、拷贝、反序列化的overhead，而且这还是单程通讯的开销。 Servlet方案的瓶颈在于线程的动态管理、调度成本高过Async I/O，但那往往是访问请求到10K/S以后的事。而且到了那个层面，优先考虑的不是单机的Scale up问题，而是整个机群的Scale out问题 关于动静态页面分离，这是一个架构的复杂度和效率的取舍。首先不要想当然认为不分离性能就不好。设计良好的servlet application自然有caching机制，用java写的hashmap在很多情况下benchmark还比native的版本高。 五、感悟在软件工程里面，重要的是好的设计和规范，难点也往往在这里，而对于实现却可以有很多种方式，只需要根据业务场景取舍就行。比如用php或者java实现一个分布式的多模块系统，对于java而言，开源的实现很多，所以在相同的条件下，选择java会更好，但是可能由于公司的技术体系需要选择php，这个时候可能就需要自己去实现一套适用于php的分布式服务框架。以后的工作和学习中应该着重加强自己在这方面的能力。 六、参考资料 Java Servlet为什么不做成FastCGI模式？ Difference between FastCGI and Java Servlet API Servlet的生命周期，Servlet和CGI的区别 搞不清FastCgi与PHP-fpm之间是个什么样的关系 维基百科fastcgi]]></content>
      <categories>
        <category>CS原理</category>
      </categories>
      <tags>
        <tag>cgi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[跳了一次JAVA泛型擦除的坑]]></title>
    <url>%2F2016%2F02%2F24%2Fjava-generic%2F</url>
    <content type="text"><![CDATA[记录一下今天在帮同事解决使用spring参数注入问题的时候由于对泛型的理解不到位而遇到的坑。 如下代码所示： 12345@RequestMapping(value="saveAll")public ResponseMsg saveAll(List&lt;Rule&gt; rules)&#123; Rule rule=rules.get(0); //这行代码在测试的时候报错了......&#125; 这段代码的意思是使用spring的参数注入功能自动完成将前端传过来的数据装载到rules变量里面。我刚开始一直认为这段代码肯定是对的，然后就一直说同事一定是前端传过来的数据有错，然后就各种检查js，debug一步一步的查，发现前端传过来的数据是正确的，后来我又想会不会是eclipse的debug功能有缺陷（原谅一个idea粉对eclipse的各种不屑），当然继续被打脸，因为我在我电脑上debug时数据是一样的，rules里面的元素居然是LinkedHashMap！！看着debug显示的数据，简直不能接受，我明明声明了rules对象只能存Rules对象啊，怎么会装其他对象！！ 然后就真的没辙了。。我就说这个问题我解决不了了，超出我认知范围啊，然后我们叫了一个正式员工过来帮我们看看。。他开始也是按我们的步骤排错，后来遇到和我们一样的问题，但是牛人终究是牛人，能想出来的导致问题的因素也比我们多，他说会不会是spring不支持这种带泛型的自动参数装载啊，毕竟泛型是要被擦除的。。 擦除。。。泛型擦除。。。我靠，我终于知道是什么原因了。之前看了那么多关于泛型擦除的居然都没有想到是这个问题！！而且这种坑当时也踩过，居然没联想起来，智商捉急。 关于泛型擦除的详细介绍具体是什么我就不写在这篇文章里面了，大概就是在编译前会执行一系列的语法检查，从而减少因为强制类型转换带来的异常，但是编译后的代码是不含泛型的，会将泛型限制的元素类型给去掉。 也就是说虽然我声明了rules只能装Rule类型的对象，但是代码被编译后，这个限制就没有了！因为通过语法检查rules里的元素确实是Rule类型的对象，所以并不需要在编译后再去检查。但是问题来了，这种检查只能检查一些显式生命的对象是不是Rule类型，而java是可以通过反射来动态的生成对象的，sprng在参数注入的时候是通过反射实现前端参数自动装载入对象的相关属性！！ 所以这样声明的问题在于，由于编译时对rules内元素类型的限制已经被擦除了，所以spring并不知道反射成那种类型的对象，于是就默认的用LinkedHashMap来装载一个对象所有的属性和值，于是rules里面的对象在运行的时候实际上是LinkedHashMap！！！所以spring可能并不支持泛型参数或者需要指定其他条件才能正确的注入泛型参数（这个还没有深究）。 至于以前踩过这方面的坑就是用Gson反序列化带泛型的对象的时候需要额外指定一个参数来说明集合里面的元素类型（具体的我忘了，这个有思路就好）。当时也是觉得很奇妙，为什么不做得智能一点自己识别，我不是已经通过泛型指定类型了么。当时也就抱怨一下，没有怎么多想，现在想起来还真是too young ， too simple。。 这件事让我明白不要盲目的相信自己的经验，计算机肯定是对的。经验解决不了的问题，就从原理一步一步去想，平时学的理论可能看起来没什么用，就好像科普一样，然而在解决一些问题时确是一针见血。多联想，发散思维才能在技术这条路上走得更远。]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>泛型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动态规划问题-怎么扔鸡蛋]]></title>
    <url>%2F2016%2F01%2F04%2Fdp-eggs-problem%2F</url>
    <content type="text"><![CDATA[在网上查资料的时候无意间看到了这道谷歌面试题，据说这道面试题刷了好多的大牛(可怕)。读了几篇文章，读懂以后感觉这种解决问题的思路和方法实在是太巧妙了，佩服！在最坏的情况下仍要保证付出最小的代价，这种思想非常值得让人去学习和借鉴，所以写一篇博客记录一下自己对这道题的理解。 题目一幢 200 层的大楼，给你两个鸡蛋，如果在第 n 层扔下鸡蛋，鸡蛋不碎，那么从第 n-1 层扔鸡蛋，都不碎。这两只鸡蛋一模一样，不碎的话可以扔无数次，且鸡蛋在0层不会碎。设计一种策略能保证可以测出鸡蛋恰好会碎的楼层，且如果该策略是最坏的情况所扔次数最少。 解决问题思维分析首先我们需要确定最坏情况是什么样子的。假设n是我们的决定第一次尝试的楼层，第一个鸡蛋从n层开始扔。 如果没有坏，那么我们就可以从[n+1,100]这个区间扔鸡蛋了，这个时候怎么扔就是我们需要考虑的策略。 但是如果运气比较背，鸡蛋坏了~_~!那么这个时候我们就只有一个鸡蛋了，所以为了满足我们要测出恰好会碎的楼层，我们只能从1楼一直扔到n-1楼。这个时候我们的最坏情况就是n次。 鸡蛋没有坏该怎么选择第二次以及以后扔鸡蛋的策略呢？由于没有碎，所以第n层对于我们而言和第0层是一样一样的，所以我们不能采用一层一层增加的方式扔鸡蛋！因为有两个鸡蛋，比较任性。下面提出几个合理的假设，然后分析： 增加n层：碎了的话，最坏情况就是我们还要扔2n-n-1+2=n+1次，这个时候最坏情况比第一次还坏，而且照这个趋势下去，最坏情况只会越来越坏，是不可控的，所以这种策略抛弃。 增加大于n层：和增加n层一样，如果第一个鸡蛋碎了那最坏情况就是越来越坏，且比增加n层更坏（可以自己做个简单的算术推导一下）。 增加小于n层：随着n的不断减小，最坏情况下需要仍的次数恒定为n是不会变的（因为第一次就碎了，对于这种情况就是最坏情况）。那么我们需要考虑的是如何使扔的次数最少，想想看，果断取n-1，这样既保证了快速找到刚好碎的楼层，又保证了最坏情况扔的次数最少。 所以我们最后的策略是增加n-1层。 以上就是一个分析过程，对于第三次，第四次….都可以递归的进行分析。由于最好情况是第一个鸡蛋一直扔到了100层，而100层与n之间是有一个函数关系的，下面就可以列出一个等式：n+(n-1)+(n-2)+…+1=100=n(n+1)/2所以n约等于14所以第一次从第十四层开始扔，最坏情况就是第一次就碎了，然后需要从1楼开始一层一层的扔，共扔14次。 编程解答以上是分析然后数学解答，还有一种代码做法，这里我就直接引用知乎大神的代码了哈。设f(n, m)为n层楼, m个蛋所需次数, 那么它就成了一道DP题1234567891011import functoolsdef f(n, m): if n == 0: return 0 if m == 1: return n ans = min([max([f(i - 1, m - 1), f(n - i, m)]) for i in range(1, n + 1)]) + 1 return ansprint(f(100, 2))print(f(200, 2)) 知乎讨论扔鸡蛋问题]]></content>
      <categories>
        <category>数据结构和算法</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Hash原理以及在java集合框架中的应用]]></title>
    <url>%2F2015%2F12%2F31%2Fhash-and-java%2F</url>
    <content type="text"><![CDATA[2015年最后一天，写篇文章记录一下我对hash算法的理解以及其在java集合框架中的应用以及其他地方的应用的大概介绍，算是一个比较系统的总结吧。文章参考了网上一些大神的文章（在文章末尾我会把参考文章写上），但是网上的文章很多都没有一个应用场景，读起来虽然知道了原理但是还是用不出来，我会结合平时做项目中遇到的一些问题来说明一些集合框架的具体使用。–致敬2015 Hash介绍基本概念Hash其实就是散列，就是把任意长度的输入，通过散列算法变成固定长度的输出，由于是不定到定长，所以这种变换是一种压缩映射，输出值的值域远远小于输入值的值域，所以不同的输入可能会有相同的输出，这就是Hash碰撞。 解决冲突 开放地址法:当关键字key的哈希地址p=H（key）出现冲突时，以p为基础，产生另一个哈希地址p1，如果p1仍然冲突，再以p为基础，产生另一个哈希地址p2，…，直到找出一个不冲突的哈希地址pi ，将相应元素存入其中。这种方法有一个通用的再散列函数形式：Hi=(H(key)+di)%m i=1，2，…，n,其中H（key）为哈希函数，m 为表长，di称为增量序列。增量序列的取值方式不同，相应的再散列方式也不同。 再hash法:当发生冲突时再次散列，如果依然冲突的话，可以变为多重散列或者结合其他解决冲突的方法使用。 链地址法:在发生冲突的地方，以链表的形式存储（HashMap就是这么做的） 建立公共溢出区:建立一个公共溢出区，将冲突的值放在溢出区。 什么是哈希表？哈希表也叫散列表，是根据关键字而直接进行访问内存存储位置的数据结构。它通过把关键字通过散列函数映射到哈希表中的一个位置来访问记录，以加快查找的速度。存放记录的数组叫做散列表。哈希表就是一种依托于数组的数据结构，只不过增加了一些规则来在数组上存储元素和访问元素。 hash在java中的应用java对象的equals和hashCode方法java中Object类默认的equals方法和==一样，是比较两个对象的地址是否相等的，hashCode方法是返回对象的存储地址的（hashCode是一个native方法哦，是通过JNI用其他语言实现的）。 但是一般情况下，我们并不需要去比较两个对象的地址（需要的时候我们完全可以用==），所以我们可以选择重写equals方法来比较对象的内容，在我们的业务逻辑里面，对于一个人物实体类，只要身份证属性相同，就可以认为这两个人相同，所以我们选择覆盖equals方法来比较身份证属性。 重写equals方法后，一定要记得重写hashCode方法，因为如果该对象如果出现在了使用了Hash表结构的java集合框架中的话，会首先比较该对象的hashCode方法，如果相同，再比较equals方法，如果相同，则覆盖之前的对象，不同，则用链表的方式存储这两个对象。试想一下，对于一个身份证信息相同的对象，如果只重写了equals方法，那么这两个在业务逻辑上应该被判断为相同的对象就会被重复存储。 java中对于equals和hashCode有两个约定： 当obj1.equals(obj2)为true时，obj1.hashCode() == obj2.hashCode()必须为true 当obj1.hashCode() == obj2.hashCode()为false时，obj1.equals(obj2)必须为false 也就是说，hashcode相等，equals可能不相等，但是equals相等代表这两个对象是是一个对象，所以hashCode必须相等。 HashMapHashMap使用数组加链表的方式实现的，当存在hashCode相同但是equals返回false的两个对象时，会使用链地址法来解决冲突。 HashMap中我们最常用的就是put(K, V)和get(K)。我们都知道，HashMap的K值是唯一的，那如何保证唯一性呢？我们首先想到的是用equals比较，没错，这样可以实现，但随着内部元素的增多，put和get的效率将越来越低，这里的时间复杂度是O(n)，假如有1000个元素，put时需要比较1000次。 实际上，HashMap很少会用到equals方法，因为HashMap通过一个哈希表管理所有元素，当我们调用put存值时，HashMap首先会调用K的hashCode方法，获取哈希码，通过哈希码快速找到某个存放位置，这个位置可以被称之为bucketIndex，通过上面所述hashCode的协定可以知道，如果hashCode不同，equals一定为false，如果hashCode相同，equals不一定为true。 所以理论上，hashCode可能存在冲突的情况，有个专业名词叫碰撞，当碰撞发生时，计算出的bucketIndex也是相同的，这时会取到bucketIndex位置已存储的元素，最终通过equals来比较，equals方法就是哈希码碰撞时才会执行的方法，所以前面说HashMap很少会用到equals。HashMap通过hashCode和equals最终判断出K是否已存在，如果hashCode和equals相等，则使用新V值替换旧V值，（若hashCode相等当equals为false，则链式存储存储解决冲突）并返回旧V值，如果不存在 ，则存放新的键值对到bucketIndex位置。存放元素的过程如下图所示： HashMap去除一个元素就很简单了，如下代码所示123456789101112131415public V get(Object key) &#123; // 若为null，调用getForNullKey方法返回相对应的value if (key == null) return getForNullKey(); // 根据该 key 的 hashCode 值计算它的 hash 码 int hash = hash(key.hashCode()); // 取出 table 数组中指定索引处的值 for (Entry&lt;K, V&gt; e = table[indexFor(hash, table.length)]; e != null; e = e.next) &#123; Object k; //若搜索的key与查找的key相同，则返回相对应的value if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) return e.value; &#125; return null; &#125; 需要注意的是在HashMap中，不是直接用的对象的hashcode作为对象存储地址的，而是再次hash，这么做可以防止重写hashCode方法以后使存储地址非法。内部hash实现如下1234static int hash(int h) &#123; h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4); &#125; （&gt;&gt;&gt;是无符号右移） HashMap内部定义了一个Entity泛型对象来存储每个键值对信息。如下所示：1234567891011121314151617static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final K key; V value; Entry&lt;K,V&gt; next; final int hash; /** * Creates new entry. */ Entry(int h, K k, V v, Entry&lt;K,V&gt; n) &#123; value = v; next = n; key = k; hash = h; &#125; ....... &#125; Entry为HashMap的内部类，它包含了键key、值value、下一个节点next，以及hash值，这是非常重要的，正是由于Entry才构成了table数组的项为链表。 HashSet知道了HashMap以后，HashSet其实就是HashMap的键的存储。所以就不赘述啦~~ hash在其他地方的应用 MD5加密是将任意长度的字符串散列成32位的定长字符串（由小写字母和数字组成）。 SSH中对证书信息进行散列获取证书信息。 SHA1加密算法也是一种运用散列进行加密的算法。 参考资料 hash表总结 维基百科hash表定义 hashCode和equals详解 hashmap深度解析]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>hash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop学习笔记之MapReduce初探]]></title>
    <url>%2F2015%2F12%2F28%2Fhadoop-learn-note-2015-12-28%2F</url>
    <content type="text"><![CDATA[基本概念 在python和swift中，map，reduce都是一种高阶函数（还有filter），那么什么是高阶函数呢？这里引用一下廖雪峰大神的总结，高阶函数就是指函数参数可以接收其他函数，还有一种函数叫作偏函数，就是指函数的返回值是一个函数。高阶函数和偏函数的概念可以阅读函数式编程一书得到参考java8的lambda表达式就是一种高阶函数的实现。 好吧，回归正题，那么什么是map，什么又是reduce呢？map：map就是指把输入的数据集中的每一个元素进行处理后输出，这种输入输出通常是键值对形式的。reduce：reduce的英文释义是规约，也就是说reduce函数是将一定的数据集进行循环的处理得到最终的结果。比如找出每个数据集中的最大值。 Mapper和ReducerMapper是泛型类型，分别是map函数的输入键，输入值，输出建和输出值，hadoop在java自带的基本类型之上还封装了一套适用于网络序列化传输的基本类型，这些类型位于or.apache.hadoop.io包中，例如Text类型相当于java的String类型。Reducer也是泛型类型，类型参数和Mapper一样，Reducer提供了强大的数据比较和抽取能力。Job是用来指定作业执行规范的，主要包括如下几步： 设置作业完整的类名 设置作业名称 设置输入和输入源（可以来自网络，可以来自文件系统） 设置map（即对数据进行处理的Mapper实现类）和设置reduce（Reducer的实现类）。 新旧api差别 参考官网 MapReduce的横向（水平）扩展 为了实现横向扩展，需要将数据存储在类似于HDFS的分布式文件系统中。 在MapReduce的作业中，有两类节点控制着作业的执行，一类是jobtracker（作业节点）和一系列的tasktracker（任务节点），一个作业是由多个任务（map任务和reduce任务）组成的。 Hadoop将数据分为大小相等的数据块，每个数据块就是一个分片，并且为每个分片指定一个map任务，由该任务来运行用户自定义的map函数从而处理分片中的每条记录。 分片的大小决定了程序的效率和资源的利用率，如果分片太小，那么管理分片的总时间和构建map任务的时间将会决定整个处理时间，如果分片太大，又没有充分利用map函数提供的处理能力，所以合适的分片大小至关重要。一个合理的分片大小大概是HDFS的一个块的大小。默认是64MB。如果超过了该大小，那么输入源的数据就会存储在两个机架上面，这样就会产生网络传输，降低了效率。 对于map任务，一般运行在输入数据存储的机器上，这样不需要使用网络带宽资源，提高了IO效率。如果该map任务在处理其他的任务，则需要协调其他机架上面的map任务来进行处理，这样还是会产生网络传输。但是这么做，会大大的减少这种情况的发生。 map任务的输出一般都是存储在任务执行的机器上面，因为map输出的数据大多是一个中间数据，只需要临时存储，在传给reduce任务处理之后，就可以删除该中间结果。如果中间数据传输给reduce任务失败，则会在另一个节点上重新运行map任务重新传输从而避免再次失败。 reduce任务可以接收来自多个map任务的输出，这之间复杂的数据传输流称为shuffle。shuffle就是怎样把map task的输出结果有效地传送到reduce端，也可以理解为 Shuffle描述着数据从map task输出到reduce task输入的这段过程。下图是官方的shuffle解释图shuffle参考资料 combiner为了减少map和reduce之间的数据传输量，充分利用集群之间的带宽，可以对map的输出执行一次或者多次的combiner函数，相当于对于单个map进行的规约操作（reduce是对于多个map任务的规约）.但是combiner的适用场景有限，例如平均数的计算可能就不适用-((x+y+z+a)/4+(b+c)/2)/2!=(a+b+c+x+y+z)/6，所以该函数的适用范围为对分片数据规约不会影响整个结果的场景。 Streaming APIStreaming API 使得我们可以用其他编程语言实现自己的map和reduce函数，例如用c++实现，提高程序的处理效率。该API使用标准输入输出流作为hadoop和不同语言编写的map和reduce任务之间的接口。当使用Streaming时需要在hadoop的运行命令里面指定streaming.jar文件的位置从而让hadoop支持其他语言。]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA Servlet工作原理]]></title>
    <url>%2F2015%2F12%2F20%2Fservlet-principle%2F</url>
    <content type="text"><![CDATA[servlet容器加载顺序 当 Servlet 容器（比如 Apache Tomcat ）启动后，会部署和加载所有 web 应用。当web 应用被加载，Servlet 容器会创建一次 ServletContext，然后将其保存在服务器的内存中。 web 应用的 web.xml 被解析，找到其中所有 servlet 、 filter 和 Listener 或 @WebServlet 、 @WebFilter 和 @WebListener 注解的内容，创建一次并保存到服务器的内存中。 对于所有过滤器会立即调用init() 。 当Servlet配置的 load-on-startup 或者 @WebServlet(loadOnStartup) 设置了一个大于 0 的值，则同样会在启动的时候立即调用 init() 方法。“load-on-startup”中的值表示那些 Servlet 会以相同顺序初始化。如果配置的值相同，会遵循 web.xml 中指定的顺序或 @WebServlet 类加载的顺序。另外，如果不设置 “load-on-startup” 值， init() 方法只在第一次 HTTP 请求命中问题中的 Servlet 时才被调用。 当 Servlet 容器停止，将卸载所有 web 应用，调用所有初始化的 Servlet 和过滤器的 destroy() 方法，最后回收 ServletContext和所有 Servlet 、Filter 与 Listener 实例。 HttpServletRequest 与 HttpServletResponseServlet 容器附加在一个 web 服务上，这个 web 服务会在某个端口号上监听 HTTP 请求，在开发环境中这个端口通常为 8080，生产环境中通常为 80。当客户端（web 浏览器）发送了一个 HTTP 请求，Servlet 容器会创建新的 HttpServletRequest 和 HttpServletResponse 对象，传递给已创建好并且请求的 URL 匹配 url-pattern 的 Filter 和 Servlet 实例中的方法，所有工作都在同一个线程中处理。 request 对象可以访问所有该 HTTP 请求中的信息，例如 request header 和 request body。response 对象为你提供需要的控制和发送 HTTP 响应方法，例如设置 header 和 body（通常会带有 JSP 文件中的 HTML 内容）。提交并完成HTTP 响应后，将回收 request 和 response 对象。 HttpSession当用户第一次访问该 web 应用时，会通过 request.getSession() 第一次获得 HttpSession 。之后 Servlet 容器将会创建 HttpSession ，生成一个唯一的 ID（可以通过 session.getId() 获取）并储存在服务器内存中。然后 Servlet 容器在该次 HTTP 响应的 Set-Cookie 头部设置一个 Cookie ，以 JSESSIONID 作为 Cookie 名字，那个唯一的 session ID 作为 Cookie 的值。 按照 HTTP cookie 规则 （正常 web 浏览器和 web 服务端必须遵循的标准），当 cookie 有效时，要求客户端（浏览器）在后续请求的 Cookie 头中返回这个 cookie。使用浏览器内置的 HTTP 流量监控器可以查看它们（在 Chrome、Firefox23+、IE9+ 中按 F12，然后查看 Net/Network 标签）。Servlet 容器将会确定每个进入的 HTTP 请求的 Cookie 头中是否存在名为 JSESSIONID 的 cookie，然后用它的值（session ID）从服务端内存中找到关联的 HttpSession 。 在 web.xml 中设置 session-timeout ，默认值为 30 分钟。超时到达之前 HttpSession 会一直存活。所以当客户端不再访问该 web 应用超过 30 分钟后，Servlet 容器就会回收这个 session。后续每个请求，即使指定 cookie 名称也不能再访问到相同的 session。Servlet 容器会创建一个新的 Cookie 。 另一方面，客户端上的 session cookie 有一个默认存活时间，该事件和该浏览器实例运行时间一样长。所以，当客户端关闭该浏览器实例（所有标签和窗口）后，这个 session 就会被客户端回收。新浏览器实例不再发送与该 session 关联的 cookie。一个新的 request.getSession() 将会返回新的 HttpSession 并设置一个拥有新 session ID 的 cookie。 概述 ServletContext 与 web 应用存活时间一样长。它被所有 session 中的所有请求共享。 只要客户端一直与相同浏览器实例的web应用交互并且没有超时，HttpSession就会存在。 HttpServletRequest 和 HttpServletResponse 的存活时间为客户端发送完成到完整的响应（web 页面）到达的这段时间。不会被其他地方共享。 所有 Servlet 、 Filter 和 Listener 对象在 web 应用运行时都是活跃的。它们被所有 session 中的请求共享。 设置在 HttpServletRequest 、 HttpServletResponse 和 HttpSession 中的所有属性在Servlet存活时都会一直保持存活。 线程安全Servlet 和 Filter 被所有请求共享。那是 Java 的一个优点，使得多个不同线程（读取 HTTP 请求）可以使用同一个实例。否则为每个请求重新创建线程的开销实在过于昂贵。 但永远不要将任何 request 或 session 域中的数据赋值给 servlet 或 filter 的实例变量。它将会被所有其他 session 中的所有请求共享。那是非线程安全的！下面的示例对这种情况进行了展示：1234567891011public class ExampleServlet extends HttpServlet &#123; private Object thisIsNOTThreadSafe; protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; Object thisIsThreadSafe; thisIsNOTThreadSafe = request.setParameter("foo"); // 不安全，为所有请求所共享 thisIsThreadSafe = request.getParameter("foo"); // 线程安全 &#125;&#125;]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>servlet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解JAVA MQ消息中间件]]></title>
    <url>%2F2015%2F12%2F15%2FMQ-learning%2F</url>
    <content type="text"><![CDATA[MQ的几种消息传递方式发布订阅模式发布订阅模式有点类似于我们日常生活中订阅报纸。每年到年尾的时候，邮局就会发一本报纸集合让我们来选择订阅哪一个。在这个表里头列了所有出版发行的报纸，那么对于我们每一个订阅者来说，我们可以选择一份或者多份报纸。比如北京日报、潇湘晨报等。那么这些个我们订阅的报纸，就相当于发布订阅模式里的topic。有很多个人订阅报纸，也有人可能和我订阅了相同的报纸。那么，在这里，相当于我们在同一个topic里注册了。对于一份报纸发行方来说，它和所有的订阅者就构成了一个1对多的关系。这种关系如下图所示： 点对点模式点对点模式就相当于打电话，由两端的双方独享这一通信链路 扩展的对点模式 和前面两种方式比较起来，request-response的通信方式很常见，但是不是默认提供的一种模式。在前面的两种模式中都是一方负责发送消息而另外一方负责处理。而我们实际中的很多应用相当于一种一应一答的过程，需要双方都能给对方发送消息。于是请求-应答的这种通信方式也很重要。它也应用的很普遍。 请求-应答方式并不是JMS规范系统默认提供的一种通信方式，而是通过在现有通信方式的基础上稍微运用一点技巧实现的。下图是典型的请求-应答方式的交互过程： 我在项目中的理解MQ其实就是一个消息中转站。在企业级的应用里，会有一个服务器集群来作为这个中转站，这个集群中有主从，有备份，有路由，有网关。此时MQ就是就是一种中间件，在个人的实验中体会不到这种感觉。企业级的MQ不仅仅实现了简单的消息中转站的功能，还实现了消息生产者和消息消费者的认证功能（即他们能消费和生产哪些具体的topic）。附一张企业MQ的架构图 MQ的缺点 mq的主要问题在于重复生产和重复消费(延迟也是一个很大的缺点，但是这可以换来性能上的提升，监听获取信息肯定比轮询获取信息的效率高)。 比如几个业务系统需要消费一个点对点模式的mq消息，其中一个业务系统消费成功了但是并没有向mq服务器成功发送消费成功的确认ack，导致消息在mq服务器中依然存在，从而导致其他业务系统的重复消费。 再比如生产者如果没有接收到mq服务器的确认消息，就会重复生产，如果在服务器没有相应的去重措施，就会带来很大的隐患。 所以在使用MQ的时候，最重要的问题不是在于怎么去用它，而是怎么在业务系统中解决重复生产和重复消费的问题。具体的得根据系统允许的容错率和业务来进行相应的处理。 我主要说一下在服务器端对MQ进行去重的方法，如果是同一topic的信息，可以通过对消息内容进行摘要运算从而达到简单的去重效果。 实现可靠MQ和去重参考方法 消息的可靠性设计，目前有2种模式：模式1是采用Notify的方式，先发送半消息，业务操作成功后最后提交完整消息，同时提供业务操作的检查接口，这种模式实现消息的最终一致性；模式2将业务数据和消息数据先都存在业务数据库里面，通过数据库的事务保证一致性，随后将消息转发给MQ。模式1的缺点是业务侵入性高，方案比较复杂，需要重新实现；模式2的缺点是消息数据可能会散落在各个地方，包括业务系统，而且可以集成现有MQ。 消息去重设计，也有2种模式：模式1是消费者根据自己的业务实现去重，模式2是在消费者端增加一个数据库表专门记录已经消费过的消息，不需要消费者根据业务去做去重。]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>MQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM内存自动管理机制]]></title>
    <url>%2F2015%2F12%2F03%2Fjvm-memory-manage%2F</url>
    <content type="text"><![CDATA[本文主要总结java虚拟机的内存管理机制,不同的数据类型存在在怎样的一块内存区域中,不同的内存区域有哪些不同点,怎样回收过了生命周期的内存,采取何种策略去回收这些对象或者常量,不同的回收算法的优缺点.什么情况下会产生内存溢出异常以及该采取怎样的措施避免内存溢出,以及一些常用的虚拟机性能监控工具和故障排除工具-&lt;&lt;深入理解java虚拟机&gt;&gt;读书笔记 jvm内存区域虚拟机管理的运行时数据区域如下图所示 方法区方法区是各个线程共享的内存区域(这样就能理解为什么需要线程同步和加锁了,当然还与java数据访问时数据复制来复制去有关),用于存储已被虚拟机加载的类信息,常量,静态变量,JIT即时编译后的代码等.方法区的数据类型复杂,而且jvm规范也没有明确指定方法区的内存使用和回收策略,所以不同的虚拟机对于方法区的内存回收都有不同的机制.下文介绍. 运行时常量池运行时常量池是方法区的一部分,存储编译时或者运行时产生的字面常量或者其他信息. 堆堆也是被各个线程共享的内存区域,虚拟机主要管理的内存区域,是java存放对象数据的地方,这里面也有指针,因为对象数据里面可能还有其他对象的引用,还有方法区常量池常量的引用.还有数组也是在堆上分配内存. 虚拟机栈线程私有,与线程同生同灭.用于存储java运行时的内存模型,也就是每个方法执行时的一个栈帧,该栈帧存储了局部变量表,操作数栈,动态链表,方法出口等运行时信息.对于一个方法开始执行到执行结束就是一个栈帧在虚拟机中入栈和出栈的过程. 程序计数器和虚拟栈帧一样,该内存区域的生命周期也是在一个线程的执行周期内.可以看作当前线程执行字节码行号的指示器,字节码的解释执行工作就是通过这个来确定循环,判断,跳转,异常处理以及线程恢复等功能.每个线程拥有一个独立的程序计数器内存区域可以使得多线程环境下线程能接着上一个时间片继续执行. 本地方法栈本地方法栈与虚拟机栈的作用几乎相同,不同的地方在于虚拟机栈用于服务java方法,而本地方法栈可以描述native方法,即虚拟机规范规定的可使用的其他语言. 直接内存直接内存不是虚拟机运行时数据取的一部分在jdk1.4后引入了一种通道和缓冲区的I/O方式,使用native函数库直接分配堆外内存,然后通过一个存储在java堆中的DirectByteBuffer对象作为这块内存的引用直接进行操作,这样能在一定的场景下显著提高性能,避免了在java堆中和native堆中来回复制数据. 数据在上述内存区域的分布 对象的两种不同访问形式 这样看句柄就是一系列的指针和其他数据组成的数据结构,果然是要好好学习数据结构 jvm内存溢出 内存溢出即指上述内存区域存放的数据结构的总量大于限制的最大大小,导致虚拟机跑出内存溢出异常. 虚拟机垃圾收集器 如何判断对象需要被回收？对于不同的算法有不同的判断方式 堆中垃圾回收算法引用计数算法给每个对象添加一个引用计数器，每当有一个地方引用它时，计数器加一，引用失效则减一。优点：实现简单，判断效率高缺点：当对象存在相互引用时，不能够回收此类对象可达性分析算法可达性算法的核心在于找到一系列的根节点，并且判断对象到这些根节点是否可达。可作为根节点的对象有： 虚拟机栈中引用的对象 方法取中静态属性引用的对象 方法取中常量引用的对象 本地方法栈中JNI引用的对象 四种引用强引用-软引用-弱引用-虚引用 方法区中垃圾回收算法标记-清除算法首先标记出所有需要回收的对象，在标记完成后统一进行回收，但是缺点就是会造成大量的内存碎片。导致之后给大的对象分配内存无可用空间。复制算法将可用的内存分为两半，一次只使用其中的一半，当使用完以后，将还活着的对象全部复制到另一半内存空间中，然后清理掉原来的那半内存，缺点就是代价太高，需要牺牲一半的内存。标记-整理算法将所有的对象像一端移动，然后直接清理掉其他的对象（98%的对象生命周期都很短）]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>jvm</tag>
        <tag>内存管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[前端开发神器emmet使用教程]]></title>
    <url>%2F2015%2F11%2F24%2Femmet-usage%2F</url>
    <content type="text"><![CDATA[Emmet的前身是大名鼎鼎的Zen coding 使用方法:结合下面的指令,然后摁下TAB键生效 该插件在eclipse,sublime,idea等开发工具上面都可以快速的安装]]></content>
      <categories>
        <category>web前端</category>
      </categories>
      <tags>
        <tag>emmet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式总结]]></title>
    <url>%2F2015%2F11%2F21%2Fcode-design%2F</url>
    <content type="text"><![CDATA[学一样东西,自己另外举个例子实现一遍,才能知道里面的原理.记录一下学习的几种基本的设计模式 文件结构几种设计模式的文件结构如下图所示源代码下载源码下载 代理模式说明 这里我举了一个网页渲染时使用代理延迟加载图片的例子,用线程的睡眠模拟延迟加载,hibernate的延迟加载就是用了代理模式实现代理模式的主要应用: 远程代理,例如webservice 虚拟代理,html渲染 安全代理,控制真实对象的访问权限 spring的AOP就是用的代理模式的思想设计实现的 类图 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687package codeDesign.proxy;/** * Created by kangbiao on 2015/11/22. * 网页绘制接口,代理和被代理类均实现该接口 */public interface Draw &#123; /** * 绘制图片，需要花很多时间，使用代理来绘制 * @param url */ void drawPicture(String url);&#125;package codeDesign.proxy;/** * Created by kangbiao on 2015/11/22. * 绘制html网页的类（该类会消耗很多时间） */public class HtmlDraw implements Draw&#123; /** * 该方法不耗时，不需要代理 * @param text */ public void drawText(String text) &#123; System.out.println("正在绘制文字:" + text); &#125; /** * 会消耗一定的时间，需要代理 * @param url */ @Override public void drawPicture(String url) &#123; System.out.println("图片区域正在从远程加载图片"); try &#123; Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("正在绘制图片:"+url); &#125;&#125;package codeDesign.proxy;/** * Created by kangbiao on 2015/11/22. * 图片绘制代理类 */public class ProxyDraw implements Draw &#123; HtmlDraw htmlDraw; public ProxyDraw()&#123; this.htmlDraw=new HtmlDraw(); &#125; @Override public void drawPicture(String url) &#123; System.out.println("代理先输出一张占位图片"); new Thread(new Runnable() &#123; @Override public void run() &#123; htmlDraw.drawPicture("1.jpg"); System.out.println("代理去掉占位图片"); &#125; &#125;).start(); &#125;&#125;package codeDesign.proxy;/** * Created by kangbiao on 2015/11/22. * 代理模式测试类 */public class ProxyTest &#123; /** * 该过程演示了网页的绘制过程，使用代理模式异步绘制网页上面的图片 * @param args */ public static void main(String[] args)&#123; HtmlDraw htmlDraw=new HtmlDraw(); htmlDraw.drawText("文字1"); ProxyDraw proxyDraw=new ProxyDraw(); proxyDraw.drawPicture("1.jpg"); htmlDraw.drawText("文字2"); &#125;&#125; 工厂模式说明 最基础的设计模式 类图 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081package codeDesign.factory;/** * Created by kangbiao on 2015/11/21. * */public class Tea &#123; private String sugar; public void mixSugarTea()&#123; System.out.print("只有"+sugar); &#125; public String getSugar() &#123; return sugar; &#125; public void setSugar(String sugar) &#123; this.sugar = sugar; &#125;&#125;package codeDesign.factory;/** * Created by kangbiao on 2015/11/21. * 蓝茶 */public class BlueTea extends Tea&#123; public void mixSugarTea()&#123; System.out.print(super.getSugar()+"蓝茶"); &#125;&#125;package codeDesign.factory;/** * Created by kangbiao on 2015/11/21. * 红茶 */public class BlackTea extends Tea&#123; public void mixSugarTea()&#123; System.out.print(super.getSugar()+"红茶"); &#125;&#125;package codeDesign.factory;/** * Created by kangbiao on 2015/11/21. * 茶的工厂类 */public class TeaFactory &#123; public static Tea getTea(String teaType)&#123; Tea tea; switch (teaType)&#123; case "black": tea=new BlackTea(); break; case "blue": tea=new BlueTea(); break; default: tea=new Tea(); break; &#125; return tea; &#125;&#125;package codeDesign.factory;/** * Created by kangbiao on 2015/11/21. * 工厂模式测试 */public class FactoryTest &#123; public static void main(String[] args)&#123; Tea tea = TeaFactory.getTea("black"); tea.setSugar("红糖"); tea.mixSugarTea(); &#125;&#125; 装饰器模式说明 如果只有一个Concrete Component类而没有抽象的Component接口时，可以让Decorator继承Concrete Component。 如果只有一个Concrete Decorator类时，可以将Decorator和Concrete Decorator合并。 java的io流包就是使用的装饰器模式 类图 代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071package codeDesign.decorator;/** * Created by kangbiao on 2015/11/21. * 汽车类 */public class Car &#123; public void showFunc()&#123; System.out.print("组装完毕"); &#125;&#125;package codeDesign.decorator;/** * Created by kangbiao on 2015/11/21. * 汽车的功能类 */public class Function extends Car&#123; protected Car car; public void addFuncs(Car car)&#123; this.car=car; &#125; public void showFunc()&#123; if (car!=null)&#123; car.showFunc(); &#125; &#125;&#125;package codeDesign.decorator;/** * Created by kangbiao on 2015/11/21. * 制动功能 */public class BrakingFunction extends Function&#123; public void showFunc()&#123; System.out.print("制动"); super.showFunc(); &#125;&#125;package codeDesign.decorator;/** * Created by kangbiao on 2015/11/21. * ABS防抱死功能 */public class ABSFunction extends Function&#123; public void showFunc()&#123; System.out.print("ABS"); super.showFunc(); &#125;&#125;package codeDesign.decorator;/** * Created by kangbiao on 2015/11/21. * 装饰模式测试 */public class DecoratorTest &#123; public static void main(String[] args)&#123; Car car=new Car(); ABSFunction abs=new ABSFunction(); BrakingFunction braking=new BrakingFunction(); abs.addFuncs(car); braking.addFuncs(abs); braking.showFunc(); &#125;&#125; 策略模式说明 这里我结合了工厂模式,使得加密算法的选择逻辑不用暴露给客户端Strategy中定义了公共算法的实现接口,然后通过多态在Context动态的创建不同的实现类的实例从而达到算法策略选择逻辑简化单元测试,因为每一个具体的实现都在一个类里面,可以分开测试减少了算法调用类和算法实现类之间的耦合 类图 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384package codeDesign.strategy;/** * Created by kangbiao on 2015/11/21. * 加密算法接口 */public interface EncryptStrategy &#123; /** * 加密算法实现接口 * @param rawString * @return */ String doEncrypt(String rawString);&#125;package codeDesign.strategy;/** * Created by kangbiao on 2015/11/21. * md5加密策略实现类 */public class MD5Strategy implements EncryptStrategy&#123; @Override public String doEncrypt(String rawString) &#123; return "MD5("+rawString+")"; &#125;&#125;package codeDesign.strategy;/** * Created by kangbiao on 2015/11/21. * SHA1加密实现类 */public class SHA1Strategy implements EncryptStrategy &#123; @Override public String doEncrypt(String rawString) &#123; return "SHA1("+rawString+")"; &#125;&#125;package codeDesign.strategy;/** * Created by kangbiao on 2015/11/21. * 加密上下文维护类，客户端调用类 */public class EncryptContext &#123; private EncryptStrategy encryptStrategy; public final static byte MD5=0; public final static byte SHA1=1; /** * 这里实现用工厂模式实现自动装载不同的类 * @param method */ public EncryptContext(Byte method)&#123; switch (method)&#123; case MD5: this.encryptStrategy=new MD5Strategy(); break; case SHA1: this.encryptStrategy=new SHA1Strategy(); break; default: break; &#125; &#125; public String doEncrypt(String rawString)&#123; return encryptStrategy.doEncrypt(rawString); &#125;&#125;package codeDesign.strategy;/** * Created by kangbiao on 2015/11/21. * 策略模式测试类 */public class EncryptTest &#123; public static void main(String[] args)&#123; EncryptContext encryptContext=new EncryptContext(EncryptContext.MD5); String result=encryptContext.doEncrypt("123456"); System.out.print(result); &#125;&#125;]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA15新特性]]></title>
    <url>%2F2015%2F11%2F17%2Fidea-15-feature%2F</url>
    <content type="text"><![CDATA[Debug 支持 Lambda 表达式 Debug ，之前版本只能使用推倒 Debug 时可强制方法 /表达式返回值 用户界面 测试 UI 提升，增加大量统计功能 “Find in Path”功能增加行内代码搜索 Run 的时候会出现小绿条，提示当前运行配置 增加对色弱 /色盲的配色支持 支持一键运行 /测试 编辑器 on-the-fly 冗余代码检测 表达式、返回值类型推断 可直接 encode 特殊的 HTML 字符，如 &gt; 会转换成 &gt; 语言 Kotlin 支持 Groovy 支持 2.3 版本中的 @Builder 注解 Scala 支持增强 框架 支持 Spring 4.2 特性 Spring Boot 支援更好，如 application.yml 、 initializer 提示与配置 Grails 支持 3.X 版本 Arquilian &lt;- 我不懂是啥 Android 增加 Android Studio 1.3 的新特性 构建工具 Gradle/SBT &lt;- 引入时选择特定 modules 前端 TypeScript React AngularJS 版本控制 可直接在 Commit dialog 窗口中修改代码 支持 Rebase 功能 分支操作 Perforce 中的 Shelve （没用过）、 TFS 、 MQ 增强 数据库工具 支持修改 Table 、多个查询窗口（终于支持了…）、执行计划（终于支持了…） 注册方法 注册码可以沿用14的,只是在 注册时选择 License server ，填 http://idea.lanyus.com ，然后点击 OK]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>idea</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bash基础复习]]></title>
    <url>%2F2015%2F11%2F17%2Fbash-review%2F</url>
    <content type="text"><![CDATA[变量用户自定义变量123name="kangbiao" #变量定义等号两边不能够有空格echo $name #输出变量值,调用变量需要在变量前加$unset name #删除name变量 数组变量定义123# 可以不用declare -a 指定该变量为数组name[0]="aaa"name[1]="bbb" 环境变量 环境变量是全局变量,用户自定义变量是局部变量(对当前shell有效)env 命令可以查看所有环境变量 语系变量 定义系统语言环境,注意linux shell是不支持中文的,只能通过插件实现终端支持中文$LANG 位置参数变量 在脚本执行时获取用户输入参数 位置变量 作用 $n n为数字,$0代表命令本身,$1-$9代表第一到第九个参数,十个以上${10} $* 获取命令行中的所有参数,$*把所有的参数当做一个整体来看 $@ 也是获取所有参数,不过把每个参数区别对待,可以for循环遍历 $# 代表命令行参数的个数 预定义变量 可用于判断命令执行结果,以及结束自身进程等 域定义变量 作用 $? 最后一次命令执行后的返回结果,为0代表成功,非0代表失败 $$ 当前进程的进程号(PID) $! 后台运行的最后一个进程的进程号(PID) read [选项] [变量名]eg:read -p “please enter your name:” name 运算符declare 命令 declare [+/-] [选项] +是取消属性,-是设定属性eg:declare -a arr 将变量arr声明为数组型eg:declare -i num 将变量num声明为整型 declare -i var 可以实现数值运算 eg:declare -i sum=num1+num2 num1和num2可以不是整型,会自动转换 export 其实就是调用了declare命令将变量声明为环境变量 数值运算123456789# 方法一 声明法a=1b=2declare -i c=$a+$b# 方法二c=$(expr $a + $b) # 执行expr命令后将命令结果返回给c,单小括号是将系统命令执行结果赋给变量# 方法三c=$(($a+$b)) #推荐c=$[$a+$b] # if判断语句使用的方法 环境变量配置文件umask 准备知识:目录刚刚创建的最大权限是777,而文件刚创建时的权限是666,即任何用户都不能执行该文件 123若umask=022则新创建的文件权限为rw-rw-rw- 抵消掉相同的权限 ----w--w- 后为 rw-r--r--新创建的目录的权限为rwxrwxrwx抵消掉相同的权限----w--w- 后为 rwxr-xr-x source file 加载环境变量配置文件 正则表达式条件判断和流程控制示例]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>bash</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[javaweb基础复习]]></title>
    <url>%2F2015%2F11%2F14%2Fjavaweb-review%2F</url>
    <content type="text"><![CDATA[JSPJSP指令标识1234基本格式:&lt;%@ 指令名 属性1="" 属性2="" %&gt;page指令:&lt;%@ page language="" contentType="text/html; charset=UTF-8" %&gt; 每个jsp必须有的标识include指令:&lt;%@ include file="jspFilePath" %&gt; 可用于包含其他文件标签库指令(taglib):&lt;%@ taglib prefix="" uri="" %&gt; ,引入该指令后可以扩展jsp文件的标签,简化jsp文件内容,常用的标签库有JSTL,SPRING,STRUCTS等. JSP动作标识12345基本格式:&lt;标识名 属性1="" 属性2=""/&gt; (支持嵌套标签)&lt;jsp:include page="静态或者动态文件的路径" flush="true|false"/&gt;&lt;jsp:forward page="重定向的目标文件地址" /&gt; 外部重定向标签,将用户请求重定向到指定页面&lt;jsp:param name="参数名" value="参数值" /&gt; 作为其他动作标识的子标识.为其他标识传递参数&lt;jsp:useBean /&gt; 内置对象 java内置对象为什么不需要实例化?因为jsp文件在被解析成一个servlet后会在其java文件里通过工厂方法获取到对应对象的实例所以jsp内置对象只是隐示的不需要实例化相应的对象.因为web容器能够自动实例化参考资料request , response , session , application , out , page , config , exception , pageContext 特殊说明 session.invalidata()方法销毁session会话,session.removeAttribute()只是移除属性application对象作用域为应用程序全局,可用于统计网站访问量,也可以通过getInitParameter(String name)方法获取web应用配置信息config对象主要用来获取web.xml中的配置信息,功能和application有所重复 简单应用 通过request.getHeader(“referer)获取请求源地址后与服务器主机地址做对比可以简单的防止跨域提交 servlet概念 servlet是一个标准,是java servlet API的实现和相关类的方法的组合,由web容器创建并管理其生命周期servlet的两种配置方式:注解配置和web.xml文件配置servlet作为业务逻辑层,将jsp中的请求响应对象放入servlet中,可以更好的将web应用分层,提高其可维护性 servlet过滤器 定义一个实现Filter类的过滤器类即可过滤器的两种配置方式:基于注解配置(在Filter实现类上加@urlPatterns={“/*”})或者在web.xml文件中配置应用:登陆过滤,字符编码过滤,个性化过滤 servlet监听器 监听web容器的有效期时间,由容器管理]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>j2ee</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VerPass接口设计文档]]></title>
    <url>%2F2015%2F10%2F23%2Festate%2F</url>
    <content type="text"><![CDATA[2015-11-20修订记录 增加安卓端检查更新接口 2015-11-12修订记录 新增获取该用户有权限的所有密钥接口 2015-10-24修订记录 返回的物业信息增加该物业所属的楼栋信息 删掉了投诉评价接口,只能上报投诉和查看投诉 2015-10-23修订记录(多角色修改): 修改了获取用户角色接口,返回角色代码由原来的单数字字段变为逗号分隔的字符串 ,因为一个用户可能是业主或者租客 修改了报修模块获取我的报修接口,数据有所增加.将图片路径直接返回,不需要作二次请求,同时增加返回维修人员信息 新增确认报修完成接口,客户端可以确认该报修已经完成.需要确认完成后才能评论.具体参见评论报修接口说明 新增上传开锁记录接口 修改获取我的所有物业接口 修改业主获取绑定用户接口 修改获取一定数量的公告接口 增加公告通过webview获取公告的接口(根据公告id获取公告详情) 将申请绑定接口从用户中心模块移到物业模块,修改了接口访问地址 该文档为描述物业管理系统服务器端与APP端的数据交互。 文档里面参数的值为全大写的地方,值的范围只能是状态码对照表规定变量的范围之内,如:USER_ROLE只能为1,2或者3中的一个,否则服务器会返回参数异常错误. 文档里面的数据为举例数据。 接口基于restful风格的URL. —— 批注(康彪) 编码规范错误代码:web端错误代码规范:采用6位数字作为错误代码最高位为0,四五位为模块代码,二三位为错误详情,最后一位作为扩展. app端错误代码规范:采用6位数字作为错误代码最高两位为1,四五位为模块代码,二三位为错误详情,最后一位作为扩展,模块位全为0为程序异常例:000030:web端00模块的03方法发生错误. 数据格式:数据格式基于jsonjsonString的值为空时为null,不会是空数组或者空字符串,基本格式如下:12345678&#123; "status": true/false, "errorMsg": &#123; "code": null/string, "description": null/string &#125;, "jsonString": array or object or null or string or basictype&#125; 如果status为false,客户端需要根据errorMsg进行相应的业务处理,如果为true,则从jsonString里面取出业务数据处理,展示 状态码对照表: 数据项 变量 app用户状态 USER_STATUS -1(禁用) 1(正常) 0(待审核) app用户角色 USER_ROLE 1(家庭成员) 2(租户) 3(业主) 性别 SEX 0(男) 1(女) 证件类型 CARD_TYPE 0(身份证) 1(军官证) 门禁权限是否可用 DOOR_AUTHORITY 0(不可用) 1(可用) 维修状态 REPAIR_STATUS 0(待处理) 1(处理中) 2(处理完待评价) 3(已评价) 费用收费单位 FEE_UNIT family(按户) square(按平米) per(按次) 账单状态 BILL_STATUS 0(未缴费) 1(已缴费) 投诉状态 COMPLAIN_STATUS 0(待处理) 1(已处理待评价) 2(已评价) 投诉主题 COMPLAIN_TYPE 0(类型一) 1(类型二) 2(类型三) 物业类型 PROPERTY_TYPE 1(商户) 2(住宅) 物业状态 PROPERTY_STATUS -1(出租) 1(自用) 车位类型 PARKLOT_TYPE 1(小车位) 2(中车位) 3(大车位) 费用类型 FEE_TYPE 0(物业费) 1(服务费) 2(车位费) 门禁密钥类型 SECRET_TYPE 1(楼栋) 2(道闸) 错误代码对照表 code 描述 错误级别 100000 客户端参数错误 高 100001 服务器未知异常 高 app端接口用户中心 (01)登陆客户端请求 请求URL:api/uc/login请求方法:GET/POST请求参数:phone: 18144240528password: md5(123456) 服务器返回数据123456789&#123; "status":false, "errorMsg": &#123; "code":10001, "description":"请输入11位手机号" &#125;, "jsonString": null&#125; 退出登陆客户端请求 请求URL:api/uc/loginOut请求方式:GET 服务器返回数据12345678&#123; "status": true, "errorMsg": &#123; "code": null, "description": null &#125;, "jsonString": null&#125; 密码找回客户端请求 请求URL:api/uc/findPassword/{userPhone}请求方式:GET 服务器返回数据12345678&#123; "status": true, "errorMsg": &#123; "code": null, "description": null &#125;, "jsonString": null&#125; 客户端请求 请求URL:api/uc/findPassword/checkVerifyCode/{code}请求方式:GET 服务器返回数据12345678&#123; "status": true, "errorMsg": &#123; "code": null, "description": null &#125;, "jsonString": null&#125; 客户端请求 请求URL:api/uc/findPassword/reset/{newPassword}请求方式:GET 服务器返回数据12345678&#123; "status": true, "errorMsg": &#123; "code": null, "description": null &#125;, "jsonString": null&#125; 注册客户端请求 请求URL:api/uc/register/getVerifyCode/{phone}请求方式:GET 服务器返回数据12345678&#123; "status": false, "errorMsg": &#123; "code": "100200/100210", "description": "电话号码已经注册/请输入正确的手机号" &#125;, "jsonString": null&#125; 客户端请求 请求URL:api/uc/register/checkVerifyCode/{verifyCode}请求方式:GET 服务器返回数据12345678&#123; "status": false, "errorMsg": &#123; "code": "100220", "description": "验证码错误" &#125;, "jsonString": null&#125; 客户端请求 请求URL:api/uc/register/doRegister请求方式:GET参数:nickname:kangbiaopassword:md5(123456) 服务器返回数据12345678&#123; "status": true, "errorMsg": &#123; "code": "100000(已经是业主)/100001(没有任何绑定)", "description": "如果已经是业主的话,后端会自动绑定所有物业,如果不是业主且没有任何绑定,则需要进入绑定物业界面,至于用户想要绑定其他物业,则可以在进入app后再绑定" &#125;, "jsonString": null&#125; 修改密码客户端请求 请求URL:api/uc/modify/password请求方式:GET参数:oldPassword:md5(123456)newPassword:md5(234568) 服务器返回数据12345678&#123; "status": false, "errorMsg": &#123; "code": null, "description": "原密码错误" &#125;, "jsonString": null&#125; 修改个人资料客户端请求 请求URL:api/uc/modify/getProfile请求方式:GET 服务器返回数据123456789101112131415161718192021&#123; "status": true, "errorMsg": &#123; "code": null, "description": null &#125;, "jsonString": &#123; "id": 1, "phone": "18144240528", "name": "康彪", "sex": 0, "birthday": 150515510000, "urgentName": "小明", "urgentPhone": "131627828989", "identityType": 1, "identityCode": "510704199405281715", "vehicleIdIst": "5426d;dsds5", "propertyIdList": "1;2", "authenticationTime": 1541214000 &#125;&#125; 客户端请求 请求URL:api/uc/modify/submitProfile请求方式:POST参数:name:姓名birthday:出生日期urgentName:紧急联系人姓名urgentPhone:紧急联系人电话identityType:CARD_TYPEidentityCode:证件号码sex:SEX 服务器返回数据12345678&#123; "status": false, "errorMsg": &#123; "code": null, "description": "原密码错误" &#125;, "jsonString": null&#125; 获取用户角色 请求URL:api/uc/getRole请求方式:GET说明:由于现在是一个用户可以有多个角色关系,所以返回的USER_ROLE的值为1,2,3中的一个或多个,用逗号分割 服务器返回数据12345678&#123; "status": true, "errorMsg": &#123; "code": null, "description": null &#125;, "jsonString": "1,2"或者"1"&#125; 推送(02)客户端请求 请求URL:api/push请求方式:GET参数:type:info: 服务器返回数据12345678&#123; "status": true, "errorMsg": &#123; "code": null, "description": null &#125;, "jsonString": null&#125; 投诉(03)增加投诉客户端请求 请求URL:api/complain/add请求方式:POST参数:title:投诉标题content:投诉内容file[]:图片 服务器返回数据12345678&#123; "status": false, "errorMsg": &#123; "code": null, "description": "图片上传错误" &#125;, "jsonString": null&#125; 获取我的投诉客户端请求 请求URL:api/complain/getMyComplain请求方式:GET参数:status:COMPLAIN_STATUS,不加参数则返回所有投诉.result为投诉处理结果说明. 服务器返回数据123456789101112131415161718192021222324252627282930313233343536373839&#123; "status": true, "errorMsg": &#123; "code": null, "description": null &#125;, "jsonString": [ &#123; "id": 5, "title": "楼下太吵", "content": "dfssad", "description": "打算倒萨", "phone": "18144240528", "time": 23663323056, "imageIdList": null, "type": 1, "status": 0, "cuId": 1, "remark": null, "result": null, "consoleUserEntity": null &#125;, &#123; "id": 18, "title": "测试投诉", "content": "测试投诉", "description": "测试投诉", "phone": "18144240528", "time": 1445666212672, "imageIdList": "/oa/file/picture/20151024135652_286.jpg,/oa/file/picture/20151024135652_263.png", "type": null, "status": 0, "cuId": null, "remark": null, "result": null, "consoleUserEntity": null &#125; ]&#125; 报修(04)增加报修客户端请求 请求URL:api/repair/add请求方式:POST参数:title:报修主题content:报修内容file[]:图片(可选字段) 服务器返回数据12345678&#123; "status": true, "errorMsg": &#123; "code": null, "description": null &#125;, "jsonString": null&#125; 获取我的报修客户端请求 请求URL:api/repair/getMyRepair请求方式:GET参数:status:REPAIR_STATUS(不加则返回所有状态的报修)说明:imageIdList为逗号分隔的图片路径的字符串,不是原来的id字符串,另外当status为1(处理中)时,维修人员信息在repairManEntity里面. 服务器返回数据12345678910111213141516171819202122232425262728293031&#123; "status": true, "errorMsg": &#123; "code": null, "description": null &#125;, "jsonString": [ &#123; "id": 15, "phone": "18144240528", "repairManId": 1, "title": "test", "content": "报修测试", "description": "报修测试", "submitTime": 1445598807245, "processTime": 1445599123885, "finishTime": null, "imageIdList": "/oa/file/picture/20151023191327_823.jpg,/oa/file/picture/20151023191327_820.jpg", "status": 1, "remark": null, "remarkText": null, "cuId": 1, "result": null, "repairManEntity": &#123; "id": 1, "phone": "15114052120", "name": "小明" &#125; &#125; ]&#125; 确认报修完成客户端请求 请求URL:api/repair/confirmFinish/{repairID}请求方式:GET 服务器返回数据12345678&#123; "status": true, "errorMsg": &#123; "code": null, "description": null &#125;, "jsonString": null&#125; 评论报修客户端请求 请求URL:api/repair/remark请求方式:POST参数:id:报修idremark:评分(0-100)comment:文字评论说明:只用当报修状态为2时才可以评论报修 服务器返回数据12345678&#123; "status": true, "errorMsg": &#123; "code": null, "description": null &#125;, "jsonString": null&#125; 费用相关(05)获取账单 请求URL:api/fee/getBill请求方式:GET参数:status:BILL_STATUS(不加则返回所有状态的账单) 服务器返回数据1234567891011121314151617181920212223242526272829&#123; "status": true, "errorMsg": &#123; "code": null, "description": null &#125;, "jsonString": [ &#123; "id": 1, "total": "400.0", "items": [ &#123; "id": "水电费", "text": "100" &#125;, &#123; "id": "停车费", "text": "100" &#125;, &#123; "id": "煤气费", "text": "200" &#125; ], "status": 0, "billTime": "1976-03" &#125; ]&#125; 物业费缴纳客户端请求 请求URL:api/fee/submitBill请求方式:POST参数:billIDs:1,2说明:客户端调用支付平台的接口后,根据返回结果判断是否成功,服务器根据回调方法判断是否成功 服务器返回数据12345678&#123; "status": false, "errorMsg": &#123; "code": null, "description": "账单缴费失败" &#125;, "jsonString": null&#125; 门禁相关06)获取门禁密钥客户端请求 请求URL:api/auth/getSecret/{symbol}请求方式:GET说明:{symbol}为唯一标识蓝牙或者wifi的值 服务器返回数据12345678910111213141516&#123; "status": true, "errorMsg": &#123; "code": null, "description": null &#125;, "jsonString": &#123; "id": 11, "controlId": 3, "symbol": "YCWY_D_001", "villageId": 4, "secret": "00000000", "password": "01234567", "type": 1 &#125;&#125; 获取该用户有权限的所有密钥客户端请求 请求URL:api/auth/getAllowSecret请求方式:GET说明:根据controlType区分楼栋,园区和道闸 服务器返回数据123456789101112131415161718192021222324252627282930313233343536&#123; "status": true, "errorMsg": &#123; "code": null, "description": null &#125;, "jsonString": [ &#123; "id": 39, "controlType": 1, "symbol": "YC_D_0012", "secret": "12345678", "password": null, "type": 1, "controlEntity": "园区一" &#125;, &#123; "id": 29, "controlType": 2, "symbol": "YC_D_002", "secret": "123456789", "password": "123456", "type": 2, "controlEntity": "园区1的楼栋1" &#125;, &#123; "id": 28, "controlType": 3, "symbol": "YC_D_001", "secret": "123456789", "password": null, "type": 1, "controlEntity": "道闸一" &#125; ]&#125; 上传开锁记录客户端请求 请求URL:api/auth/uploadDoorLog请求方式:POST参数：symbol:蓝牙或者wifi的唯一标识status:０(失败)／１(成功)description:开门失败的描述（失败后必须返回该字段）level:严重级别（０为软件故障，１为门禁硬件故障，２为用户手机因素，３为用户操作有误，４为其他。失败后必须返回该字段）说明:如果status为false,应该把错误信息写入ａｐｐ日志. 服务器返回数据12345678&#123; "status": true, "errorMsg": &#123; "code": null, "description": null &#125;, "jsonString":null&#125; 物业相关(07)获取所有园区客户端请求 请求URL:api/query/getAllVillage请求方式:GET 服务器返回数据12345678&#123; "status": true, "errorMsg": &#123; "code": null, "description": null &#125;, "jsonString": [&#123;"id":1,"text":"园区一"&#125;,&#123;"id":2,"text":"园区二"&#125;]&#125; 根据园区id获取所有的楼栋客户端请求 请求URL:api/query/getBuilding/{villageID}请求方式:GET 服务器返回数据12345678&#123; "status": true, "errorMsg": &#123; "code": null, "description": null &#125;, "jsonString": [&#123;"id":1,"text":"楼栋一"&#125;,&#123;"id":2,"text":"楼栋二"&#125;]&#125; 根据园区id和楼栋id获取所有的物业客户端请求 请求URL:api/query/getProperty请求方式:GET参数:villageID:2buildingID:3 服务器返回数据12345678&#123; "status": true, "errorMsg": &#123; "code": null, "description": null &#125;, "jsonString": [&#123;"id":1,"text":"物业一"&#125;,&#123;"id":2,"text":"二"&#125;]&#125; 用户申请绑定客户端请求 请求URL:api/property/bind请求方式:POST参数:role:USER_ROLEvillageID:1buildingID:2propertyID:2 服务器返回数据12345678&#123; "status": false, "errorMsg": &#123; "code": null, "description": "您已申请或已经绑定到该物业,请不要重复申请" &#125;, "jsonString": null&#125; 获取我的所有物业客户端请求 请求URL:api/property/getMyPropery请求方式:GET说明:每个propertyEntity均对应一种用户角色(userRole),status字段为表明该绑定是待审核还是已通过审核.通过userRole字段判断该物业是我名下的物业还是我申请绑定的物业. 服务器返回数据1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071&#123; "status": true, "errorMsg": &#123; "code": null, "description": null &#125;, "jsonString": [ &#123; "id": 1, "status": 1, "userRole": 3, "propertyEntity": &#123; "id": 28, "code": "A001", "location": "半山蓝湾一单元", "type": 1, "propertySquare": 115.55, "ownerType": 1, "villageId": 5, "buildingId": 1, "status": 1, "openDoorStatus": 1, "modifyTime": 1445581460913, "buildingEntity": &#123; "id": 1, "villageId": 5, "description": "", "buildingCode": "G1B1", "buildingName": "园区1的楼栋1", "villageEntity": &#123; "id": 5, "code": "YQ001", "name": "园区一", "description": "" &#125; &#125; &#125; &#125;, &#123; "id": 2, "status": 1, "userRole": 3, "propertyEntity": &#123; "id": 29, "code": "A002", "location": "半山蓝湾二单元", "type": 1, "propertySquare": 222.11, "ownerType": 1, "villageId": 5, "buildingId": 1, "status": 1, "openDoorStatus": 1, "modifyTime": 1345504275966, "buildingEntity": &#123; "id": 1, "villageId": 5, "description": "", "buildingCode": "G1B1", "buildingName": "园区1的楼栋1", "villageEntity": &#123; "id": 5, "code": "YQ001", "name": "园区一", "description": "" &#125; &#125; &#125; &#125; ]&#125; 业主获取绑定用户客户端请求 请求URL:api/property/getBind请求方式:GET参数:status:USER_STATUS,不加则返回所有状态的绑定说明:如下例子代表xiaoming和xiaozhang分别请求以家庭成员和租客的身份绑定到物业编号为A001的物业上面,根据status得出两人的状态都是待审核.该示例数据仅为一个物业的绑定审核,一个业主会有多个物业,bindId字段标识一个绑定关系. 服务器返回数据123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&#123; "status": true, "errorMsg": &#123; "code": null, "description": null &#125;, "jsonString": [ &#123; "propertyEntity": &#123; "id": 28, "code": "A001", "location": "半山蓝湾一单元", "type": 1, "propertySquare": 115.55, "ownerType": 1, "status": 1, "openDoorStatus": 1, "modifyTime": 1445581460913, "buildingEntity": &#123; "id": 1, "description": "", "buildingCode": "G1B1", "buildingName": "园区1的楼栋1", "villageEntity": &#123; "id": 5, "code": "YQ001", "name": "园区一", "description": "" &#125; &#125; &#125;, "bindUserInfos": [ &#123; "bindId": 5, "role": 2, "status": 0, "appUserEntity": &#123; "phone": "13981111434", "nickname": "xiaozhang", "status": 1, "registerTime": 155515151500, "lastLogin": 155212121000 &#125; &#125;, &#123; "bindId": 6, "role": 1, "status": 0, "appUserEntity": &#123; "phone": "15114052120", "nickname": "xiaoming", "status": 1, "registerTime": 155212121000, "lastLogin": 155212121000 &#125; &#125; ] &#125; ]&#125; 业主审核绑定客户端请求 请求URL:api/property/submitBind/{operate}/{bindId}请求方式:GET说明:operate只能为agree或者refuse,bindId为上面审核绑定返回数据中的bindId字段 服务器返回数据12345678&#123; "status": true, "errorMsg": &#123; "code": null, "description": null &#125;, "jsonString": null&#125; 公告 (08)获取一定数量的公告客户端请求 请求URL:api/notice/getSome/{number}请求方式:GET说明:number为获取的公告的数量,最新公告优先返回.picturePathList以逗号分隔,没有图片则为null.注意content为null并不表示该公告详情为空,因为列表显示公告时不需要该字段,所以后台设为了null 服务器返回数据12345678910111213141516171819202122232425&#123; "status": true, "errorMsg": &#123; "code": null, "description": null &#125;, "jsonString": [ &#123; "id": 6, "title": "周本顺杨栋梁严重违纪被双开", "description": "河北省委原书记、省人大常委会原主任周本顺严重违纪被开除党籍和公职", "content": null, "createTime": 1444977998184, "picturePathList": "/oa/file/picture/20151023191327_823.jpg,/oa/file/picture/20151023191327_820.jpg" &#125;, &#123; "id": 4, "title": "测试公告", "description": "描述", "content": null, "createTime": 1444899774481, "picturePathList": "/oa/file/picture/20151023171656_889.jpg" &#125; ]&#125; 根据公告id获取公告详情客户端请求 请求URL:api/notice/getContent/{noticeID}请求方式:GET说明:返回内容为该公告的html代码,通过webview显示只会返回公告详情公告标题和发布时间需要客户端自行组装. 服务器返回数据1H5网页 版本检查 (09)客户端请求 请求URL:api/query/checkUpdate请求方式:GET 服务器返回数据123456789101112&#123; "status": true, "errorMsg": &#123; "code": null, "description": null &#125;, "jsonString": &#123; "path": "/oa/file/apk/test.apk", "versionCode": "v1.1.2", "description": "修复门禁bug" &#125;&#125;]]></content>
      <categories>
        <category>接口文档</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[JAVA基础知识复习笔记]]></title>
    <url>%2F2015%2F10%2F22%2Fjava-review%2F</url>
    <content type="text"><![CDATA[java程序初始化:静态代码快优先与非静态代码块(优先于构造函数),父类优先于子类进行初始化 没有声明任何方法的接口为标识接口,用来判断某个类属于特定的类型,用instanceof判断是否是某个接口,类或者抽象类的实现 JAVA浅复制和深复制:都需要实现Cloneable标识接口.当一个类只包含基本数据类型是,使用浅复制即可复制该对象,但是包含其他对象是,需要在clone方法中对每个属性进行深复制. JAVA创建对象的四种方法:new , 反射 , 类的复制 , 反序列化 JAVA实现回调函数的方法:通过定义一个接口,然后在接口中声明要调用的方法,接着实现该接口,在需要调用的地方把该类接口类型(相当于c++的函数指针)作为参数传进去,实际使用是传入该接口不同的实现类的对象即可. JAVA中多态的机制:编译时多态(通过方法的重载实现),运行时多态(通过方法的重写实现) native关键字:native关键字说明其修饰的方法是一个原生态方法，方法对应的实现不是在当前文件，而是在用其他语言（如C和C++）实现的文件中。Java语言本身不能对操作系统底层进行访问和操作，但是可以通过JNI接口调用其他语言来实现对底层的访问。 当子类需要显式的调用父类的构造函数时,super()必须是第一条语句. JAVA跳出多层循环:在需要跳出的地方设置一个标识,然后在break(break out;此处out即为标识,类似于goto语句的使用)语句后天添加标识即可. final是指引用不可变,但是对于引用的对象可以改变 Math类中ceil,round,floor的区别 new String(“abc”)创建了几个对象 对象默认的equals方法是比较的引用 StringBuilder的效率高于StringBuffer,但是其不是线程安全的 try catch中如果有return语句,但是依旧会执行finally里面的语句,但是如果finally里面有return语句的话,会覆盖其他return语句 异常:异常分为运行时异常和普通异常,分别为Error和Exception类,均继承自Throwable类,运行时异常会导致程序的终止执行,而普通异常用户可以自己处理 JAVA中的两种IO流,字节流(InputStream和OutputStream)和字符流(Reader和Writer,其他流继承自这两种类从而实现不同的功能 JAVA集合框架:List,Set,Map,迭代器Iterator,]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[数据结构和算法复习-链表]]></title>
    <url>%2F2015%2F10%2F21%2Farchitecture-review%2F</url>
    <content type="text"><![CDATA[单向链表的基本操作 定义:每个节点存储了当前节点的数据信息和下一个节点的地址信息或者引用 JAVA实现:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960//定义节点信息类class Node&#123; Node next=null; int data; public Node(data)&#123; this.data=data; &#125;&#125;public class LinkedList&#123; Node head=null; //插入一个节点方法一 public void addNode(int data)&#123; Node newNode=new Node(data); if (head==null) &#123; head=newNode; return; &#125; Node tmp=head; while(tmp.next!=null)&#123; tmp=tmp.next; &#125; tmp.next=newNode; &#125; //删除一个节点 public boolean deleteNode(int index)&#123; if(index&lt;1||index&gt;this.length()) return false; if (index==1) &#123; head=head.next; return true; &#125; int i=1; Node preNode=head; Node curNode=preNode.next; while(curNode!=null)&#123; if (i==index) &#123; preNode.next=curNode.next; return true; &#125; preNode=curNode; curNode=curNode.next; i++; &#125; return true; &#125; //获取链表的长度 public int length()&#123; int len=0; Node tmp=head; if (tmp.next!=null) &#123; len++; tmp=tmp.next; &#125; return len; &#125;&#125;]]></content>
      <categories>
        <category>数据结构和算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu下eclipse tomcat jdk8组合进行j2ee开发]]></title>
    <url>%2F2015%2F10%2F20%2Fubuntu%E4%B8%8Beclipse%20tomcat%20jdk8%E7%BB%84%E5%90%88%E8%BF%9B%E8%A1%8Cj2ee%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[下载jdk1.8最新版本，解压在/usr/local/java目录下 sudo gedit /etc/profile 修改环境变量配置文件，这里的配置是对所有应用程序生效 在文件后面添加上述四行 source /etc/profile 使修改生效 如果系统中有多个jdk，输入一下命令切换默认的jdk sudo update-alternatives –install /usr/bin/java java /usr/local/java/jdk1.8.0_45/bin/java 300sudo update-alternatives –install /usr/bin/javac javac /usr/local/java/jdk1.8.0_45/bin/javac 上述命令是将java和javac两个配置到系统的候选命令里面 sudo update-alternatives –display javasudo update-alternatives –config javasudo update-alternatives –config java -version 下载eclipse，官网下载后解压即可。 下载tomcat，官网下载后解压即可。 配置eclipse开发j2ee环境细节略过。添加tomcat服务器过程中遇到的问题。 权限问题，由于将tomcat解压在了opt目录下，所以需要更改解压目录的权限 sudo chmod -R 777 apache-tomcat-8.0.22/ 端口占用问题，修改apache-tomcat-8.0.22/conf/server.xml的端口，默认是8080端口 无法添加tomcat服务器的问题，eclipse版本不支持，需要下载最新的版本。另一个问题时没法点下一步，需要执行如下操作 退出 eclipse到[工程目录下]/.metadata/.plugins/org.eclipse.core.runtime把org.eclipse.wst.server.core.prefs和 org.eclipse.jst.server.tomcat.core.prefs这两个文件去掉重启eclipsetomcat启动配置文件错误，删除tomcat服务器，并且勾选同时删除配置。重新添加tomcat服务器即可]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>j2ee</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql主从架构原理和实现]]></title>
    <url>%2F2015%2F10%2F19%2Fmysql-master-slaves%2F</url>
    <content type="text"><![CDATA[高性能Mysql主从架构的复制原理及配置详解]]></content>
      <categories>
        <category>SQL&amp;NoSQL</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[总结一下最近整合spring和hibernate遇到的问题]]></title>
    <url>%2F2015%2F10%2F14%2F%E6%80%BB%E7%BB%93%E4%B8%80%E4%B8%8B%E6%9C%80%E8%BF%91%E6%95%B4%E5%90%88spring%E5%92%8Chibernate%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[刚开始学习javaee,把自己遇到的主要问题总结一下,做个笔记,也希望给别人带来帮助,spring和hibernate均是&gt;基于当前最新版本的上一个版本.4.3.7和4.3.11 [toc] 遇到的问题:配置文件问题在配置hibernate的session工厂的时候,读取不到.hbm.xml文件的原因大致如下:12这是我的配置&lt;property name="mappingLocations" value="classpath:estate/entity/database/*.hbm.xml"/&gt; 少加了classpath: 如果是用的maven进行项目的依赖管理的话,检查maven是否将资源文件放入了输出目录里面,即需要对pom.xml文件进行如下配置,(我是这个问题).1234567891011121314151617181920212223&lt;build&gt; &lt;finalName&gt;test&lt;/finalName&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;include&gt;**/*.tld&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;include&gt;**/*.tld&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt; spring不能对hibernate进行事务管理:我百度后发现出现这个问题的原因很多 没有在web.xml里面配置OpenSessionInViewFilter拦截器将请求的url和hibernate会话绑定在一起 在配置spring-servlet扫描的报的时候将事务管理的包页扫描进去了,导致spring不能进行事务管理,(好像是新版本的问题)需要进行如下配置12345&lt;!-- 配置spring自动扫描的包,如果开启了事务管理,一定要过滤掉相应的类 --&gt; &lt;context:component-scan base-package="estate"&gt; &lt;context:include-filter type="annotation" expression="org.springframework.stereotype.Controller"/&gt; &lt;context:exclude-filter type="regex" expression=".*ServiceImpl"/&gt; &lt;/context:component-scan&gt; 代码编写问题spring事务管理后抛出的异常不能再service和dao里面捕捉到我的解决方案是在控制器里面加入捕捉异常的代码:1234567891011try &#123; noticeService.add(noticeEntity); &#125; catch (Exception e) &#123; LogUtil.E("上传公告图片写入数据库失败"); basicJson.getErrorMsg().setCode("100103"); basicJson.getErrorMsg().setDescription("公告增加失败,请检查您的输入"); return basicJson; &#125; google了一下,发现有其他的方法可以在service和dao里面捕捉异常,但是我觉得spring这样的设计比较合理,在业务逻辑层进行处理,而service只提供业务逻辑需要调用的方法. 参考项目目录结构 配置文件web.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566&lt;web-app xmlns="http://xmlns.jcp.org/xml/ns/javaee" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd" version="3.1"&gt; &lt;!-- 加载spring上下文配置文件 --&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:config/applicationContext*.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.util.Log4jConfigListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;!-- 将网站根目录写入系统属性 --&gt; &lt;context-param&gt; &lt;param-name&gt;webAppRootKey&lt;/param-name&gt; &lt;param-value&gt;WEB.ROOT&lt;/param-value&gt; &lt;/context-param&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.util.WebAppRootListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;!-- 配置spring拦截器 --&gt; &lt;servlet&gt; &lt;servlet-name&gt;estateOA&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:config/spring-servlet.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;estateOA&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;!-- 将url请求会话和hibernate会话绑定在一起,使得spring对hibernate可以进行事务管理 --&gt; &lt;filter&gt; &lt;filter-name&gt;openSession&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.orm.hibernate4.support.OpenSessionInViewFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;singleSession&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;openSession&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;!-- spring security认证拦截器 --&gt; &lt;filter&gt; &lt;filter-name&gt;springSecurityFilterChain&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.DelegatingFilterProxy&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;springSecurityFilterChain&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt;&lt;/web-app&gt; spring上下文123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:context="http://www.springframework.org/schema/context" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:tx="http://www.springframework.org/schema/tx" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:mvc="http://www.springframework.org/schema/mvc" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.0.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd"&gt; &lt;!-- 导入hibernate表单验证bean --&gt; &lt;import resource="validator-bean.xml"/&gt; &lt;context:component-scan base-package="estate"/&gt; &lt;!-- 导入外部的properties文件 --&gt; &lt;context:property-placeholder location="classpath:config/db.properties"/&gt; &lt;!-- 配置c3p0的连接池 --&gt; &lt;bean id="dataSource" class="com.mchange.v2.c3p0.ComboPooledDataSource"&gt; &lt;property name="jdbcUrl" value="$&#123;jdbcUrl&#125;"/&gt; &lt;property name="driverClass" value="$&#123;driverClass&#125;"/&gt; &lt;property name="user" value="$&#123;dbuser&#125;"/&gt; &lt;property name="password" value="$&#123;password&#125;"/&gt; &lt;property name="initialPoolSize" value="$&#123;initialPoolSize&#125;"/&gt; &lt;property name="minPoolSize" value="$&#123;minPoolSize&#125;"/&gt; &lt;property name="maxPoolSize" value="$&#123;maxPoolSize&#125;"/&gt; &lt;property name="acquireIncrement" value="$&#123;acquireIncrement&#125;"/&gt; &lt;property name="maxStatements" value="$&#123;maxStatements&#125;"/&gt; &lt;property name="maxStatementsPerConnection" value="$&#123;maxStatementsPerConnection&#125;"/&gt; &lt;property name="maxIdleTime" value="$&#123;maxIdleTime&#125;"/&gt; &lt;/bean&gt; &lt;!-- 配置hibernate的SessionFactory --&gt; &lt;bean id="sessionFactory" class="org.springframework.orm.hibernate4.LocalSessionFactoryBean"&gt; &lt;property name="dataSource" ref="dataSource"&gt; &lt;/property&gt; &lt;property name="hibernateProperties"&gt; &lt;props&gt; &lt;prop key="hibernate.dialect"&gt;org.hibernate.dialect.MySQLDialect&lt;/prop&gt; &lt;prop key="hibernate.show_sql"&gt;true&lt;/prop&gt; &lt;prop key="hibernate.format_sql"&gt;true&lt;/prop&gt; &lt;prop key="hibernate.hbm2ddl.auto"&gt;update&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; &lt;property name="mappingLocations" value="classpath:estate/entity/database/*.hbm.xml"/&gt; &lt;/bean&gt; &lt;!-- 配置声明式事务管理 --&gt; &lt;bean id="txManager" class="org.springframework.orm.hibernate4.HibernateTransactionManager"&gt; &lt;property name="sessionFactory" ref="sessionFactory"/&gt; &lt;/bean&gt; &lt;!-- 配置方法的隔离级别 --&gt; &lt;tx:advice id="txAdvice" transaction-manager="txManager"&gt; &lt;tx:attributes&gt; &lt;tx:method name="get*" read-only="true"/&gt; &lt;tx:method name="save*" propagation="REQUIRED" read-only="false"/&gt; &lt;tx:method name="add" propagation="REQUIRED"/&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;!-- 配置事务切点 --&gt; &lt;aop:config&gt; &lt;aop:pointcut id="txPoint" expression="execution(* estate.service.*.*(..))"/&gt; &lt;aop:advisor advice-ref="txAdvice" pointcut-ref="txPoint"/&gt; &lt;/aop:config&gt;&lt;/beans&gt; spring-servlet.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354 &lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:mvc="http://www.springframework.org/schema/mvc" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd"&gt; &lt;context:annotation-config/&gt; &lt;!-- 配置spring自动扫描的包,如果开启了事务管理,一定要过滤掉相应的类 --&gt; &lt;context:component-scan base-package="estate"&gt; &lt;context:include-filter type="annotation" expression="org.springframework.stereotype.Controller"/&gt; &lt;context:exclude-filter type="regex" expression=".*ServiceImpl"/&gt; &lt;/context:component-scan&gt; &lt;mvc:annotation-driven/&gt; &lt;mvc:resources mapping="/view/**" location="/view/"/&gt; &lt;mvc:resources mapping="/file/**" location="/file/"/&gt; &lt;!-- 以json,xml,html返回数据 --&gt; &lt;bean class="org.springframework.web.servlet.view.ContentNegotiatingViewResolver"&gt; &lt;property name="order" value="1"/&gt; &lt;property name="mediaTypes"&gt; &lt;map&gt; &lt;entry key="json" value="application/json"/&gt; &lt;entry key="xml" value="application/xml"/&gt; &lt;entry key="html" value="text/html"/&gt; &lt;/map&gt; &lt;/property&gt; &lt;property name="defaultViews"&gt; &lt;list&gt; &lt;bean class="org.springframework.web.servlet.view.json.MappingJackson2JsonView"/&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!--jsp解析 --&gt; &lt;bean id="viewResolver" class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;property name="viewClass" value="org.springframework.web.servlet.view.JstlView"/&gt; &lt;property name="prefix" value="/WEB-INF/jsp/"/&gt; &lt;property name="suffix" value=".jsp"/&gt; &lt;/bean&gt; &lt;!-- 文件上传 --&gt; &lt;bean id="multipartResolver" class="org.springframework.web.multipart.commons.CommonsMultipartResolver"&gt; &lt;property name="maxUploadSize" value="10485760"/&gt; &lt;property name="defaultEncoding" value="UTF-8"/&gt; &lt;property name="resolveLazily" value="true"/&gt; &lt;/bean&gt;&lt;/beans&gt; pom.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;groupId&lt;/groupId&gt; &lt;artifactId&gt;estateOA&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-core&lt;/artifactId&gt; &lt;version&gt;4.3.11.Final&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-validator&lt;/artifactId&gt; &lt;version&gt;5.1.3.Final&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.validation&lt;/groupId&gt; &lt;artifactId&gt;validation-api&lt;/artifactId&gt; &lt;version&gt;1.1.0.Final&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt; &lt;artifactId&gt;gson&lt;/artifactId&gt; &lt;version&gt;2.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.34&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-orm&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-expression&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aop&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aspects&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.7.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cglib&lt;/groupId&gt; &lt;artifactId&gt;cglib&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-api&lt;/artifactId&gt; &lt;version&gt;2.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-core&lt;/artifactId&gt; &lt;version&gt;2.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.tomcat&lt;/groupId&gt; &lt;artifactId&gt;tomcat-catalina&lt;/artifactId&gt; &lt;version&gt;8.0.22&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-codec&lt;/groupId&gt; &lt;artifactId&gt;commons-codec&lt;/artifactId&gt; &lt;version&gt;1.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-logging&lt;/groupId&gt; &lt;artifactId&gt;commons-logging&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-httpclient&lt;/groupId&gt; &lt;artifactId&gt;commons-httpclient&lt;/artifactId&gt; &lt;version&gt;3.0.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;dom4j&lt;/groupId&gt; &lt;artifactId&gt;dom4j&lt;/artifactId&gt; &lt;version&gt;1.6.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;jaxen&lt;/groupId&gt; &lt;artifactId&gt;jaxen&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;c3p0&lt;/groupId&gt; &lt;artifactId&gt;c3p0&lt;/artifactId&gt; &lt;version&gt;0.9.1.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.5.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-fileupload&lt;/groupId&gt; &lt;artifactId&gt;commons-fileupload&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;test&lt;/finalName&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;include&gt;**/*.tld&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;include&gt;**/*.tld&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt;&lt;/project&gt;]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>hibernate</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu下ftp服务器搭建]]></title>
    <url>%2F2015%2F08%2F23%2Fubuntu%E4%B8%8Bftp%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[apt-get install vsftpd 安装ftp服务器端vim /etc/vsftpd.conf 编辑ftp服务器的配置 如果设置了*anonymous_enable=YES*则表示可以匿名登陆12chroot_list_enable=YESchroot_list_file=/etc/vsftpd.chroot_list 启用这兩项的话，根目录要设置为不可写 添加用户 由于用户组在安装的时候已经默认添加了用户组ftp，所以直接添加用户即可 useradd kangbiao -g ftp -d /var/www/heyunjiang -s /sbin/nologinpasswd kangbiao 设置新添加用户的密码 还需要在编辑/etc/shells文件，在末行加入/sbin/nologin 新建的目录要将权限设为777才可进行ftp访问（很笨的做法，只需要保证ftp用户组的权限为7就行） 每次编辑ftp配置后记得 service vsftpd restart重启ftp服务器使更改生效]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>vsftpd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu下apache服务器开启url重写]]></title>
    <url>%2F2015%2F08%2F07%2Fubuntu%E4%B8%8Bapache%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%BC%80%E5%90%AFurl%E9%87%8D%E5%86%99%2F</url>
    <content type="text"><![CDATA[sudo gedit /etc/apache2/apache2.conf 打开apache配置文件 12345Directory /var/www/&gt; 实际目录根据网站根目录而定 Options Indexes FollowSymLinks AllowOverride None 改为All Require all granted&lt;/Directory&gt; ln -s /etc/apache2/mods-avaliable/rewrite.load /etc/apache2/mods-enable/rewrite.load 建立url重写模块的软连接，apache会自动加载（前提是apache2.conf中配置了加载mods-enable中的模块，默认是加载） 在网站的根目录下建立.htaccess文件，内容为： 1234567&lt;IfModule mod_rewrite.c&gt; Options +FollowSymlinks RewriteEngine On RewriteCond %&#123;REQUEST_FILENAME&#125; !-d RewriteCond %&#123;REQUEST_FILENAME&#125; !-f RewriteRule ^(.*)$ index.php/$1 [QSA,PT,L]&lt;/IfModule&gt; 重启apache服务。。必须是root才能重启]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>apache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[crontab在Ubuntu下的使用]]></title>
    <url>%2F2015%2F07%2F06%2Fcrontab%E5%9C%A8Ubuntu%E4%B8%8B%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[crontab配置文件 crontab -e 编辑当前用户的任务列表 crontab -l 查看计划任务列表配置文件格式 * command 号分别对应 分钟0-59 小时0-23 日期1-31 月份1-12 星期0-7 中间以空格分开 例子： 每晚21:31重启Apache服务器 131 21 * * * service apache2 restart 每月的1,22,24,日的3:30重启Apache 130 3 1,22,24 * * service apache2 restart 每月的20-30号的3:30重启Apache 130 3 20-30 * * service apache2 restart 每隔两分钟重启Apache 12*/2 * * * * service apache2 restart0-59/2 * * * * service apache2 restart 晚上11点到早上7点，每隔一小时重启Apache 10 23-7/1 * * * service apache2 restart 每天18点到23点每隔30分钟重启Apache 12 */30 18-23 * * * service apache2 restart0-59/30 18-23 * * * service apache2 restart 含义 a,b,c逗号分隔表示a或b或c三个时间点执行任务 a-b表示a到b这个时间段执行任务 */a表示每a分钟或者小时或者天或者月或者星期执行任务]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>crontab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu14.04下安装php开发环境]]></title>
    <url>%2F2015%2F07%2F01%2FUbuntu14.04%E4%B8%8B%E5%AE%89%E8%A3%85php%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[切换用户为root：su root(如果没有为root设置密码，就需要sudo passwd为root设置密码，不然不能切换)。 安装服务器组件：apt-get install apache2 php5 mysql-server php5-mysql。 运行cat /etc/apache2/mod–enabled/php5.load命令查看Apache和php解析器是否关联。 运行cat /etc/php5/mods-available/mysql.ini命令查看php解析器和mysql组件是否关联成功。如果提示没有那个文件或目录就用ls命令找到mysql.ini文件。 重启Apache和mysql服务：service apache2 restart;service mysql restart。 安装成功后如下： 测试安装是否成功，打开vim输入下面的代码 vim info.php（需要注意的是Apache的默认根目录是www/html，略坑。。） 搜狗截图20150308161145.png 在浏览器访问服务器ip地址+info.php出现熟悉的phpinfo界面就成功啦~ 安装扩展包apt-get install php5-gd curl libcurl3 libcurl3-dev php5-curl然后重启Apache服务器加载扩展包 在php.info页面查看扩展包是否安装成功。]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mongodb入门笔记]]></title>
    <url>%2F2015%2F02%2F05%2Fmongodb%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[基本语法：mongodb内置的帮助功能非常实用。需要查看哪一级操作的帮助，直接xxx.help()即可，便会列出所有可用的操作.后面会有英文说明，看说明就知道对应的方法是干什么用的。 概念：mongodb存储结构： db(相当于关系型数据库中的数据库)：共用同一个索引的collections的集合collection(相当于关系型数据库中的表)：共用一个索引的documents的集合。document(相当于关系性数据库中的一行记录，即一个实体对象)：共用一个索引的对象属性的集合。可见mongodb中把关系型数据库中的包含存储关系变为索引式的存储方式。以二进制表示的json数据格式（BSON）存储数据，用索引加快读取速度，所以mongodb这类非关系型数据库的读取速度会比关系型数据库快很多。mongodb中的索引：为了提高查询和更新速度，mongodb使用了间接索引，应用程序可以把部分collections存储在一个读取速度很快的数据结构中方便读取 CURD操作：查询操作 原理：在mongodb中，一个查询的对象是一系列共用一个索引的文档的集合，也就是一个collection。查询的时候根据查询的准则和条件返回documents结果。例子：db.test.find({age:{$gt:19}}).sort({age:1}) 查询test集合中年龄大于19的对象的集合，并且按照年龄从小到大排序。 db.table1.find({name:’kangbiao’},{id:1})默认会选择_id字段，如果不需要则添加_id:0排除此字段 12&#123; "_id" : ObjectId("555d83b941e0463f63076431"), "id" : 1 &#125;&#123; "_id" : ObjectId("555d83de41e0463f63076432"), "id" : 1 &#125; db.table1.find({name:’kangbiao’},{_id:1}) 12&#123; "_id" : ObjectId("555d83b941e0463f63076431") &#125;&#123; "_id" : ObjectId("555d83de41e0463f63076432") &#125; db.table1.find({name:’kangbiao’},{_id:0}) 12&#123; "id" : 1, "name" : "kangbiao", "sex" : 1 &#125;&#123; "id" : 1, "name" : "kangbiao", "sex" : 1, "pwd" : "dsadasda" &#125; 插入操作 例子： db.test.insert({age:19,name:’xiaoming’,pwd:’adgsfsdsdfs’}) 将小明这个对象插入到test集合中。 附一张图说明mongodb查询过程：为一个collection创建索引加快查询速度 db.test.creatIndex({name:1}) 为test增加一个name索引，索引为顺序排列。]]></content>
      <categories>
        <category>SQL&amp;NoSQL</category>
      </categories>
      <tags>
        <tag>mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建gitlab服务器]]></title>
    <url>%2F2015%2F01%2F20%2Fhow-to-gitlab%2F</url>
    <content type="text"><![CDATA[写在前面 好久都没有写文章了,最近被一个项目忙得死去活来.今天恰巧没什么事儿,记录一下安装gitlab的全过程. 安装前的准备 一台服务器(ubuntu或者centos) 去gitlab官网下载deb或者rpm包到本地 这是传送门 按照gitlab官网说明安装好 curl openssh-server ca-certificates postfix依赖组件 开始安装 将下载好的gitlab安装包上传至服务器(我用的是最新的8.0版本). dpkg -i gitlab-ce-XXX.deb 开始安装 安装好以后执行gitlab-ctl reconfigure初始化配置gitlab 至此安装结束 注意事项 如果之前有安装postgresql,需要预先设置gitlab的数据库 请确定你的服务器的内存大于2个G,否则一定要挂载一个交换分区使得分区之和为2个G以上,这是gitlab能够运行的基本条件.这点非常重要!! 如何挂载交换分区参见下面 若有其他问题一定要google,不要百度! 1234567mkdir /swapcd /swapsudo dd if=/dev/zero of=swapfile bs=1M count=2k 创建交换分区使用的文件mkswap swapfile 创建交换分区swapon swapfile 挂载交换分区自动挂载交换文件sudo gedit /etc/fstab 在最后添加“/swap/swapfile swap swap defaults 0 0” 个性化设置 作为一名优羞~~的程序员,当然要自己配置一番.个性化配置包括:自定义登陆页,设置邮箱,解决头像显示 自定义登陆页 找到 /opt/gitlab/embedded/service/gitlab-rails/app/views/layouts/devise.html.haml 编辑即可,不会haml可以谷歌在线搜索一个html转haml的就行.这个很基础,我是把自带的登陆信息删了,然后通过后台管理配置(等会说)来自定义登录页面. 在admin area里面的setting选项卡里面可以通过markdown的格式自定义登陆页. 设置邮箱 我设置的是腾讯企业邮 为gitlab服务器分配一个企业邮箱账号(git@kangbiao.org) 在服务器的/etc/gitlab下找到gitlab.rb编辑邮件设置(这个网上很多,不赘述) 测试一下 解决头像显示问题 在服务器的/etc/gitlab下找到gitlab.rb编辑avatar设置选项,换成duoshuo的服务器即可. 使以上配置生效 重新执行gitlab-ctl reconfigure即可,注意如果该文件没有变动的话,重新配置不会更新模板文件. 贴一下我的配置文件12345678910111213141516171819202122232425262728external_url 'http://139.129.130.62'############################# gitlab.yml configuration #############################gitlab_rails['gitlab_email_enabled'] = truegitlab_rails['gitlab_email_from'] = 'git@kangbiao.org'gitlab_rails['gitlab_email_display_name'] = 'git-kangbiao'gitlab_rails['gravatar_plain_url'] = 'http://gravatar.duoshuo.com/avatar/%&#123;hash&#125;?s=%&#123;size&#125;&amp;d=identicon'gitlab_rails['gravatar_ssl_url'] = 'https://secure.duoshuo.com/avatar/%&#123;hash&#125;?s=%&#123;size&#125;&amp;d=identicon'################################# GitLab email server settings #################################gitlab_rails['smtp_enable'] = truegitlab_rails['smtp_address'] = "smtp.exmail.qq.com"gitlab_rails['smtp_port'] = 25gitlab_rails['smtp_user_name'] = "git@kangbiao.org"gitlab_rails['smtp_password'] = "*******"gitlab_rails['smtp_domain'] = "exmail.qq.com"gitlab_rails['smtp_authentication'] = "login"gitlab_rails['smtp_enable_starttls_auto'] = true################ GitLab user ################user['git_user_name'] = "git-kangbiao"user['git_user_email'] = "git@kangbiao.org" 开始使用 gitlab支持从其他仓库导入版本库,于是我将github上的项目全部导入了进来 创建成员. 创建组.添加成员到该组.gitlab中组的权限应用于该组所拥有的所有项目,但是会被项目权限覆盖.使用组的概念可以将一个团队加入该组,然后该团队的项目的命名空间改为该组可以对项目进行很好的管理. 创建项目,创建项目时需要指明命名空间,如果是选择组的话,则组的权限应用于该项目,如果指明人的话,则该人为项目的拥有者 一些截图]]></content>
      <categories>
        <category>版本管理</category>
      </categories>
      <tags>
        <tag>gitlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设置了ssh key仍需要输入用户名和密码]]></title>
    <url>%2F2015%2F01%2F14%2F%E8%AE%BE%E7%BD%AE%E4%BA%86ssh%20key%E4%BB%8D%E9%9C%80%E8%A6%81%E8%BE%93%E5%85%A5%E7%94%A8%E6%88%B7%E5%90%8D%E5%92%8C%E5%AF%86%E7%A0%81%2F</url>
    <content type="text"><![CDATA[用的是https而不是ssh。 更新一下origin git remote remove origingit remote add origin git@github.com:Username/Your_Repo_Name.gitgit branch –set-upstream-to=origin/master master 对于HTTPS方式，可以在~/.netrc文件里设定用户名密码 machine github.comlogin Usernamepassword Password]]></content>
      <categories>
        <category>版本管理</category>
      </categories>
      <tags>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ngix uwsgi django组合建站]]></title>
    <url>%2F2015%2F01%2F07%2Fngix%20uwsgi%20django%E7%BB%84%E5%90%88%E5%BB%BA%E7%AB%99%2F</url>
    <content type="text"><![CDATA[由于最近要做一个创新项目，需要用到python web开发，于是研究了一下django这个很全能的python web框架。 为什么需要ngix呢？首先说一下为什么需要这三者组合建站，只用django的话，不能做到负载均衡，比如需要请求一些静态资源，就需要django全部去处理，不能将请求合理分发，而ngix正好能解决这样的问题（似乎这个项目也不用怎么考虑负载均衡哈~~但是提高逼格总是必须的），ngix通过配置可以将一些动态请求发给django处理，而对于静请求则自己处理，另外如果网站上还要运行php页面，那么ngix绝对是一个很好的选择，将对php的请求分发给apache处理，ngix和apache通过socket端口通信，然后返回给客户端处理后的结果。 然后为什么又需要uwsgi呢？WSGI是一种Web服务器网关接口。它是一个Web服务器（如nginx）与应用服务器（如uWSGI服务器）通信的一种规范。然后uwsgi是实现了uwsgi和WSGI两种协议的Web服务器。简单点说就是运用uwsgi我们可以实现由uwsgi启动django，然后ngix通过端口与uwsgi通信，在这个过程中，gjango实现了wsgi服务器的功能，ngix实现了wsgi客户端的功能，只不过在web里面，ngix扮演的又是服务器（计算机中的软件通信有很多都是客户端服务器模式。如文件资源就是一个服务，然后应用程序实现了了相应的协议从而去调用这个服务）。这样就实现了uwsgi在ngix和django的中转。 为什么不让ngix直接与django通信呢？uWSGI，既不用wsgi协议也不用fcgi协议，而是自创了一个uwsgi的协议，据说该协议大约是fcgi协议的10倍那么快。uWSGI的主要特点如下： 超快的性能。 低内存占用（实测为apache2的mod_wsgi的一半左右）。 多app管理。 详尽的日志功能（可以用来分析app性能和瓶颈）。 高度可定制（内存大小限制，服务一定次数后重启等）。 这三者之间的原理如下， the web client &lt;-&gt; the web server(nginx) &lt;-&gt; the socket &lt;-&gt; uwsgi &lt;-&gt; Django 开始部署安装ngix sudo apt-get install ngix由于我的机器上面还有apache，我需要修改ngix的监听端口为8080修改如下1234567server &#123; listen 8080 default_server; listen [::]:8080 default_server ipv6only=on; root /var/ngix; #将根目录改为/var/ngix index index.html index.htm;&#125; 安装django用python自带的包管理器easy_install安装 easy_install django会自动安装最新版本 安装uwsgi apt-get install python-dev #不安装这个，下面的安装可能会失败pip install uwsgi 如果是apt-get安装就需要 sudo apt-get install uwsgi-plugin-python 工具安装好以后就可以开始配置项目了，我用的开发环境是pycharm，可以自动生成django项目，如果不是需要运行django的admin.py生成相应的项目文件下面是我的项目的结构.└── myproject ├── app │ ├── admin.py │ ├── init.py │ ├── migrations │ │ └── init.py │ ├── models.py │ ├── tests.py │ └── views.py ├── db.sqlite3 ├── manage.py ├── myproject │ ├── django.xml │ ├── init.py │ ├── init.pyc │ ├── settings.py │ ├── settings.pyc │ ├── urls.py │ ├── urls.pyc │ ├── wsgi.py │ └── wsgi.pyc ├── templates django.xml文件内容为：123456&lt;uwsgi&gt; &lt;socket&gt;127.0.0.1:8630&lt;/socket&gt; &lt;chdir&gt;/var/ngix/myproject/myproject&lt;/chdir&gt; &lt;pythonpath&gt;..&lt;/pythonpath&gt; &lt;module&gt;wsgi&lt;/module&gt;&lt;/uwsgi&gt; 这里需要注意的是wsgi模块，网上很多都是错误的，直接用自动生成的就行。用socket和ngix进行通信，端口号为本机的8630端口然后需要在ngix的配置文件中添加1234location / &#123; include uwsgi_params; uwsgi_pass 127.0.0.1:8630;&#125; uwsgi是ngix自带的模块重启ngix服务，然后启动uwsgi服务 $ uwsgi -x django.xml –plugin python 需要在django.xml所在目录执行 最后在浏览器输入127.0.0.1：8080就可以看见django的调试页面了~~ 总结一下学到的其他东西：删除/etc/dpkg/info/下面对应的安装文件，可以解决apt子进程启动出错的问题。删了以后需要autoremove一下 资料分享：wsgi概念 uwsgi概念 基于nginx和uWSGI在Ubuntu上部署Django如何把uwsgi交给supervisor管理 unavailable-modifier-requested-0解决办法uwsgi手册 uwsgi部署django常见问题汇总 django中文教程 还是建议去看英文教程，完整点如上便是我参考的资料]]></content>
      <categories>
        <category>PYTHON</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>ngix</tag>
        <tag>uwsgi</tag>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql数据库优化]]></title>
    <url>%2F2015%2F01%2F02%2Fdatabase-optimize%2F</url>
    <content type="text"><![CDATA[注：数据库基于我的博客数据库设计 对COUNT的优化同时查询分类为PHP和JAVA的文章数的总数：SELECT COUNT (topic=php) AS ‘php文章数’ ,COUNT(topic=java) AS ‘JAVA文章数’ FROM article;注意count函数不会对null值进行计数，所以如果 对null进行计数，就需要加上 or null 子查询的优化将子查询优化成连接查询，但优化以后可能存在一对多的关系，如果不需要一对多，就需要distinct去除重复SELECT FROM TABLE1 WHERE id IN (SELECT id FROM TABLE2 WHERE id=1)SELECT FROM TABLE1 JOIN TABLE2 ON TABLE1.id=TABLE2.id子查询相当于是做多次判断，把所有满足ON 后面条件的结果都返回 GROUP BY 的优化两张表关联查询需要做GROUP BY统计，就先在一张表里面做GROUP BY统计后在使用连接的方式进行查询 limit查询的优化由于LIMIT子句一般是配合ORDER BY 使用，所以如果有order by 就使用主键进行排序，然后使用limit的时候记录上一次扫描的地方，不过此方法局限性很大，不合适用于主键不连续的地方 数据库结构的优化 使用可以存在数据的最小数据类型 使用简单的数据类型，int比varchar类型在mysql的处理上更加简单 尽量少用text类型，非用不可时考虑分表]]></content>
      <categories>
        <category>SQL&amp;NoSQL</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[python使用postgresql-momoko配置]]></title>
    <url>%2F2014%2F09%2F14%2Fmomoko%2F</url>
    <content type="text"><![CDATA[size参数:int含义:最小的连接数 max_size参数:int含义:最大的连接数 cursor_factory参数:psycopg2.extensions.cursor的子类含义:设置以后可以写一个psycopg2.extensions.cursor的子类,添加日志记录功能或者预先的数据库结果处理,格式化execute执行失败后的异常好处:可以很大程度的提高程序的灵活性,可以重新将事务封装在这个子类里面,而不用在每个执行SQL语句的地方都要写事务.但是这样做只能保证单条语句或者没有关联的多条语句的事务提交和回滚,对于多个插入语句,并且这条语句需要上条语句的返回结果时,实现不是很灵活. 例子:1234567891011121314151617181920212223242526272829import psycopg2import psycopg2.extensionsimport loggingclass LoggingCursor(psycopg2.extensions.cursor): def execute(self, dict): logger = logging.getLogger('sql_debug') logger.info(self.mogrify(sql, args)) try: psycopg2.extensions.cursor.execute(self, "BEGIN") for sql in dict.keys(): psycopg2.extensions.cursor.execute(self, sql, dict[sql]) psycopg2.extensions.cursor.execute(self, "COMMIT") except Exception, exc: psycopg2.extensions.cursor.execute(self, "ROLLBACK") logger.error("%s: %s" % (exc.__class__.__name__, exc)) raiseconn = psycopg2.connect(DSN)cur = conn.cursor(cursor_factory=LoggingCursor)sql_args=&#123; "INSERT INTO mytable VALUES (%s, %s, %s)":(10, 20, 30), "INSERT INTO mytable VALUES (%s, %s, %s)":(11,12,13)&#125;# 可以自动完成事务cur.execute(sql_args)这样就能够在执行的时候打印出sql语句和自定义异常 raise_connect_errors参数:bool含义:当初始化数据库连接失败后是否抛出连接异常,异常类为 class momoko.PartiallyConnectedError reconnect_interval参数: int含义:当数据库连接失败的时候,设置每多少毫秒重新尝试连接. setsession参数:list含义:在一个事务中同时执行一个列表中的所有SQL语句,如果某条SQL语句执行失败了,就关闭执行这写SQL语句的会话,并且回滚事务. auto_shrink参数:bool含义:当指定了数据库连接池的max-size后,会自动回收超过最小连接数的连接.当连接数达到最大时才会触发该函数执行连接回收. shrink_period参数:datetime.timedelta()含义:设置多久执行一次连接回收,前提是设置了auto_shrink为true. shrink_delay参数:datetime.timedelta()含义:设置多久(时,分,秒)没有用的连接被回收.前提是设置了auto_shrink为true.但是如果回收了连接后的连接数小于最小连接,就不会被回收.]]></content>
      <categories>
        <category>PYTHON</category>
      </categories>
      <tags>
        <tag>momoko</tag>
        <tag>python</tag>
        <tag>postgresql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记录一下对datatable这个表格插件的使用]]></title>
    <url>%2F2014%2F09%2F14%2Fdatatable%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[配置先上一段代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162function initDataTable()&#123; editTable=$('#tenantListTable').DataTable(&#123; "processing":true, "serverSide": true, "ajax":&#123; "url": urlConfig.tenantList, "dataSrc": "jsonString" &#125;, "columnDefs": [&#123; "targets": 0, "data": "tenantId", "visible": false, "orderable": false, "searchable": false &#125;,&#123; "targets": 1, "data": null, "orderable": false, "searchable": false, "defaultContent": "&lt;button id='detailRow' class='btn btn-primary' type='button'&gt;查看&lt;/button&gt;" &#125;,&#123; "targets": 2,//删除 "data": null, "orderable": false, "searchable": false, "defaultContent": "&lt;button id='editRow' class='btn btn-primary' type='button'&gt;编辑&lt;/button&gt;&amp;ensp;" + "&lt;button id='delRow' class='btn btn-primary' type='button'&gt;删除&lt;/button&gt;" &#125; ], "aaSorting": [[ 1, "asc" ]], "autoWidth":false, "sDom": "&lt;'box-content'&lt;'col-sm-6'f&gt;&lt;'col-sm-6 text-right'l&gt;&lt;'clearfix'&gt;&gt;rt&lt;'box-content'&lt;'col-sm-6'i&gt;&lt;'col-sm-6 text-right'p&gt;&lt;'clearfix'&gt;&gt;", "language": &#123; "emptyTable": "没有相关数据", "info": "显示 _START_ 到 _END_ 条, 共 _TOTAL_ 条记录", "infoEmpty": "没有相关数据", "infoFiltered": "(筛选自 _MAX_ 条记录)", "infoPostFix": "", "thousands": ",", "lengthMenu": "每页显示 _MENU_ 条", "loadingRecords": "加载中", "processing": "数据处理中", "search": "搜索:", "zeroRecords": "没有找到匹配数据", "paginate": &#123; "first": "首页", "last": "末页", "next": "下一页", "previous": "上一页" &#125;, "aria": &#123; "sortAscending": ":正序", "sortDescending": ":倒序" &#125; &#125; &#125;); &#125; 这段代码已经可以很好的理解在使用datatable时的基础配置了.dataSrc可以指定datatable从哪里去解析数据. 特别配置对于sDom的配置:ftrip分别代表的含义是:搜索框,表格部分,进度条,数据信息和分页块,可以说是sDom这个属性可以决定整个datatable的样式. 接下来比较实用的就是render这个配置:12345678910111213$(document).ready(function() &#123; $('#example').DataTable( &#123; "columnDefs": [ &#123; "render": function ( data, type, row ) &#123; return data +' ('+ row[3]+')'; &#125;, "targets": 0 &#125;, &#123; "visible": false, "targets": [ 3 ] &#125; ] &#125; );&#125; ); render可以对数据进行预处理渲染,比如说时间戳数据可以格式化为不同格式的时间或者将一些代码转换为明文. 插件TableTools 可以给datatable添加按钮,例如通过flash将当前的表格数据导成excel或者pdf之类的 12345678910"oTableTools": &#123; "sSwfPath": "plugins/datatables/copy_csv_xls_pdf.swf", "aButtons": [ &#123; "sExtends": "collection", "sButtonText": '保存 &lt;span class="caret" /&gt;', "aButtons": [ "csv", "xls" ] &#125; ] &#125; bootstrap 将datatable转换为bootstrap的样式直接引入dataTables.bootstrap.js就行,下面是我写的一个例子 123456789function LoadDatatables()&#123; $.getScript('plugins/datatables/jquery.dataTables.js', function()&#123; $.getScript('plugins/datatables/ZeroClipboard.js', function()&#123; $.getScript('plugins/datatables/TableTools.js', function()&#123; $.getScript('plugins/datatables/dataTables.bootstrap.js', callback); &#125;); &#125;); &#125;); &#125; editor 这个插件功能非常强大,但是需要收费,我只试用了一下,几乎可以完成所有对表格的操作,可以用户体验很好.哪位大神有源码求发邮箱. 官网 datatable]]></content>
      <categories>
        <category>web前端</category>
      </categories>
      <tags>
        <tag>datatable</tag>
      </tags>
  </entry>
</search>
